{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting the data and all that good stuff (need to do any time you want to edit/re-run)"
      ],
      "metadata": {
        "id": "-p4AabJIXr6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stzzag6OXrC2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Access the shared folder\n",
        "shared_folder_path = \"/content/drive/My Drive/Levy Lab/Value updating project/online analysis/subject data\"\n",
        "\n",
        "# Dictionary to hold DataFrames for each participant\n",
        "participant_data = {}\n",
        "participants_without_data = []\n",
        "\n",
        "# Iterate through each subject folder\n",
        "for subject_folder in os.listdir(shared_folder_path):\n",
        "    subject_folder_path = os.path.join(shared_folder_path, subject_folder)\n",
        "\n",
        "    # Check if the item is a directory (subject folder)\n",
        "    if os.path.isdir(subject_folder_path):\n",
        "        # Construct the path to the task CSV file (e.g., 654_task.csv)\n",
        "        task_file_name = f\"{subject_folder}_task.csv\"\n",
        "        task_file_path = os.path.join(subject_folder_path, task_file_name)\n",
        "\n",
        "        # Check if the task file exists\n",
        "        if os.path.exists(task_file_path):\n",
        "            # Read the task CSV file into a DataFrame\n",
        "            df = pd.read_csv(task_file_path)\n",
        "\n",
        "            # Store the DataFrame in the dictionary with the subject ID as the key\n",
        "            participant_data[subject_folder] = df\n",
        "            #print(f\"Data loaded successfully for participant {subject_folder}.\")\n",
        "        else:\n",
        "            participants_without_data.append(subject_folder)\n",
        "            print(f\"No data found for participant {subject_folder}.\")\n",
        "\n",
        "# Report the number of participants\n",
        "total_participants = len(participant_data) + len(participants_without_data)\n",
        "print(f\"\\nTotal participants processed: {total_participants}\")\n",
        "\n",
        "# Final message based on loading status\n",
        "if not participants_without_data:\n",
        "    print(\"Data loaded successfully for all participants.\")\n",
        "else:\n",
        "    print(\"Some participants did not have data loaded:\")\n",
        "    for participant in participants_without_data:\n",
        "        print(f\"- {participant}\")\n",
        "\n",
        "# Optional: Print the loaded data (commented to avoid long output)\n",
        "# for participant_id, df in participant_data.items():\n",
        "#     print(f\"Participant ID: {participant_id}\")\n",
        "#     print(df.head())  # Print the first few rows of the current participant's DataFrame\n",
        "\n",
        "# Avoid scroll-in-the-scroll in the entire Notebook\n",
        "from IPython.display import Javascript\n",
        "def resize_colab_cell():\n",
        "    display(Javascript('google.colab.output.setIframeHeight(0, true, {maxWidth: 100}, {maxHeight: 5000})'))\n",
        "get_ipython().events.register('pre_run_cell', resize_colab_cell)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter participants (exclude those who were too late on over 10% of their trials)"
      ],
      "metadata": {
        "id": "p3lOIWvYXw9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Path to the shared folder containing the subject data folders\n",
        "shared_folder_path = \"/content/drive/My Drive/Levy Lab/Value updating project/online analysis/subject data\"\n",
        "\n",
        "# List to store DataFrames for each participant\n",
        "all_participants_data = []\n",
        "\n",
        "# Iterate through each subject folder in the shared folder\n",
        "for subject_folder in os.listdir(shared_folder_path):\n",
        "    subject_folder_path = os.path.join(shared_folder_path, subject_folder)\n",
        "\n",
        "    # Check if the item is a directory (subject folder)\n",
        "    if os.path.isdir(subject_folder_path):\n",
        "        # Construct the path to the task CSV file (e.g., 654_task.csv)\n",
        "        task_file_name = f\"{subject_folder}_task.csv\"\n",
        "        task_file_path = os.path.join(subject_folder_path, task_file_name)\n",
        "\n",
        "        # Check if the task CSV file exists\n",
        "        if os.path.exists(task_file_path):\n",
        "            # Read the task CSV file into a DataFrame\n",
        "            df = pd.read_csv(task_file_path)\n",
        "\n",
        "            # Add a column for the subject ID\n",
        "            df['Subject ID'] = subject_folder\n",
        "\n",
        "            # Append the DataFrame to the list\n",
        "            all_participants_data.append(df)\n",
        "            #print(f\"Data loaded for participant {subject_folder}.\")\n",
        "        else:\n",
        "            print(f\"Task data file not found for participant {subject_folder}.\")\n",
        "\n",
        "# Report the number of participants\n",
        "total_participants = len(all_participants_data)\n",
        "print(f\"\\nTotal participants processed: {total_participants}\")\n",
        "\n",
        "# Concatenate all participant DataFrames into a single DataFrame for analysis\n",
        "all_participants_df = pd.concat(all_participants_data, ignore_index=True)\n",
        "\n",
        "# Initialize lists for valid participants and excluded subjects\n",
        "valid_participants = []\n",
        "excluded_subjects = []\n",
        "\n",
        "# Filter participants who were too late on over 10% of their trials\n",
        "for subject_id, df in all_participants_df.groupby('Subject ID'):\n",
        "    too_late_trials = df[df['Outcome'] == 'na'].shape[0]\n",
        "    total_trials = df.shape[0]\n",
        "    if (too_late_trials / total_trials) < 0.1:\n",
        "        valid_participants.append(subject_id)\n",
        "    else:\n",
        "        excluded_subjects.append(subject_id)\n",
        "\n",
        "# Filter the DataFrame to only include valid participants\n",
        "all_participants_df = all_participants_df[all_participants_df['Subject ID'].isin(valid_participants)]\n",
        "\n",
        "# Report the total number of valid participants and the excluded subjects\n",
        "print(f\"Excluded subjects: {excluded_subjects}\")\n",
        "print(f\"Total number of valid participants: {len(valid_participants)}\")\n",
        "\n",
        "print(all_participants_df.head())  # Display the first few rows of the combined DataFrame\n",
        "\n",
        "# Save the combined data to a CSV for future analysis\n",
        "all_participants_df.to_csv(\"/content/drive/My Drive/Levy Lab/Value updating project/online analysis/all_participants_data_filtered.csv\", index=False)"
      ],
      "metadata": {
        "id": "1Art9qVXXxlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Basic demographic info"
      ],
      "metadata": {
        "id": "_jr0KkY3X3ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the survey responses CSV file\n",
        "survey_responses_path = \"/content/drive/My Drive/Levy Lab/Value updating project/online analysis/subject data/survey_responses.csv\"\n",
        "\n",
        "# Load the survey responses CSV into a DataFrame with encoding specified\n",
        "survey_df = pd.read_csv(survey_responses_path, encoding='ISO-8859-1')\n",
        "\n",
        "# Transpose the survey DataFrame to make each subject's data a row\n",
        "survey_df = survey_df.transpose()\n",
        "\n",
        "# Set the first row as the header\n",
        "survey_df.columns = survey_df.iloc[0]\n",
        "survey_df = survey_df.drop(survey_df.index[0])\n",
        "\n",
        "# Convert columns to appropriate types\n",
        "survey_df['survey_age'] = pd.to_numeric(survey_df['survey_age'], errors='coerce')\n",
        "categorical_columns = [\n",
        "    'survey_gender',\n",
        "    'survey_ethnicity',\n",
        "    'survey_race',\n",
        "    'survey_handedness',\n",
        "    'survey_semaglutide',\n",
        "    'food_insecurity',\n",
        "    'learning_disabilities',\n",
        "    'survey_eaten_status_v2_v2'\n",
        "]\n",
        "\n",
        "for col in categorical_columns:\n",
        "    survey_df[col] = survey_df[col].astype('category')\n",
        "\n",
        "# List of specified demographic variables of interest\n",
        "demographic_vars = [\n",
        "    'survey_age',\n",
        "    'survey_gender',\n",
        "    'survey_ethnicity',\n",
        "    'survey_race',\n",
        "    'survey_handedness',\n",
        "    'BMI',\n",
        "    'survey_eaten_status_v2_v2',\n",
        "    'food_insecurity',\n",
        "    'survey_semaglutide',\n",
        "    'learning_disabilities',\n",
        "    'bes_GLOBAL'\n",
        "]\n",
        "\n",
        "# Ensure we have the 'valid_participants' from previous codes\n",
        "# valid_participants = [...]  # List of valid subjects\n",
        "\n",
        "# Filter the DataFrame to include only valid participants\n",
        "valid_survey_df = survey_df[survey_df.index.isin(valid_participants)]\n",
        "\n",
        "# Select only the specified demographic variables\n",
        "valid_survey_df = valid_survey_df[demographic_vars]\n",
        "\n",
        "# Initialize a dictionary to store summary statistics\n",
        "summary_stats = {}\n",
        "\n",
        "# Compute descriptive statistics for continuous variables (mean and standard deviation)\n",
        "continuous_vars = ['survey_age', 'BMI', 'bes_GLOBAL']\n",
        "for var in continuous_vars:\n",
        "    mean_value = valid_survey_df[var].astype(float).mean()\n",
        "    std_value = valid_survey_df[var].astype(float).std()\n",
        "    summary_stats[var] = {'Mean': f\"{mean_value:.2f}\", 'SD': f\"{std_value:.2f}\"}\n",
        "\n",
        "# Compute counts for categorical variables\n",
        "for col in categorical_columns:\n",
        "    value_counts = valid_survey_df[col].dropna().value_counts().to_dict()\n",
        "    summary_stats[col] = value_counts\n",
        "\n",
        "# Create a summary DataFrame for better visualization\n",
        "summary_df = pd.DataFrame.from_dict(summary_stats, orient='index')\n",
        "\n",
        "print(\"Summary Descriptive Statistics for Valid Participants:\")\n",
        "print(summary_stats)"
      ],
      "metadata": {
        "id": "ogbNjcJuX4Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data normality & average accuracy time course (separated by start group)"
      ],
      "metadata": {
        "id": "k0VIB6YjX5qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import shapiro, normaltest\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Assuming congruent_data and incongruent_data are defined and contain the data.\n",
        "\n",
        "# Combine the accuracy data into a single DataFrame for congruent and incongruent starts\n",
        "congruent_acc_df = pd.concat(congruent_data, axis=1)\n",
        "incongruent_acc_df = pd.concat(incongruent_data, axis=1)\n",
        "\n",
        "# Combine all accuracy data for overall normality tests\n",
        "all_acc_df = pd.concat([congruent_acc_df, incongruent_acc_df], axis=1)\n",
        "\n",
        "# Clean data by removing NaN values\n",
        "congruent_acc_values = congruent_acc_df.values.flatten()\n",
        "congruent_acc_values = congruent_acc_values[~np.isnan(congruent_acc_values)]\n",
        "\n",
        "incongruent_acc_values = incongruent_acc_df.values.flatten()\n",
        "incongruent_acc_values = incongruent_acc_values[~np.isnan(incongruent_acc_values)]\n",
        "\n",
        "all_acc_values = all_acc_df.values.flatten()\n",
        "all_acc_values = all_acc_values[~np.isnan(all_acc_values)]\n",
        "\n",
        "# Plot histograms and Q-Q plots for all data\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(all_acc_values, kde=True, bins=30, color='green')\n",
        "plt.title('Histogram of Overall Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sm.qqplot(all_acc_values, line='s')\n",
        "plt.title('Q-Q Plot of Overall Accuracy')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Perform Shapiro-Wilk test for normality on all data\n",
        "stat, p = shapiro(all_acc_values)\n",
        "print(f'Overall Shapiro-Wilk Test: Statistics={stat}, p={p}')\n",
        "\n",
        "# Perform D'Agostino's K-squared test for normality on all data\n",
        "stat, p = normaltest(all_acc_values)\n",
        "print(f'Overall D\\'Agostino\\'s K-squared Test: Statistics={stat}, p={p}')\n",
        "\n",
        "# Plot histograms and Q-Q plots for congruent data\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(congruent_acc_values, kde=True, bins=30, color='blue')\n",
        "plt.title('Histogram of Congruent Start Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sm.qqplot(congruent_acc_values, line='s')\n",
        "plt.title('Q-Q Plot of Congruent Start Accuracy')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Perform Shapiro-Wilk test for normality on congruent data\n",
        "stat, p = shapiro(congruent_acc_values)\n",
        "print(f'Congruent Shapiro-Wilk Test: Statistics={stat}, p={p}')\n",
        "\n",
        "# Perform D'Agostino's K-squared test for normality on congruent data\n",
        "stat, p = normaltest(congruent_acc_values)\n",
        "print(f'Congruent D\\'Agostino\\'s K-squared Test: Statistics={stat}, p={p}')\n",
        "\n",
        "# Plot histograms and Q-Q plots for incongruent data\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(incongruent_acc_values, kde=True, bins=30, color='red')\n",
        "plt.title('Histogram of Incongruent Start Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sm.qqplot(incongruent_acc_values, line='s')\n",
        "plt.title('Q-Q Plot of Incongruent Start Accuracy')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Perform Shapiro-Wilk test for normality on incongruent data\n",
        "stat, p = shapiro(incongruent_acc_values)\n",
        "print(f'Incongruent Shapiro-Wilk Test: Statistics={stat}, p={p}')\n",
        "\n",
        "# Perform D'Agostino's K-squared test for normality on incongruent data\n",
        "stat, p = normaltest(incongruent_acc_values)\n",
        "print(f'Incongruent D\\'Agostino\\'s K-squared Test: Statistics={stat}, p={p}')"
      ],
      "metadata": {
        "id": "m4580i4oX-oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import wilcoxon, chi2_contingency\n",
        "\n",
        "# Assuming all_participants_df is already created with the combined data\n",
        "\n",
        "# Initialize empty lists to store aggregated data\n",
        "all_block_counts = []\n",
        "all_block_accuracy = []\n",
        "all_trial_type_accuracy = []\n",
        "all_wilcoxon_p_values_tt = []\n",
        "all_overall_accuracy = []\n",
        "all_image_rating_data = []\n",
        "all_chi2_p_values = []\n",
        "congruent_start_data = {'congruent': [], 'incongruent': []}\n",
        "incongruent_start_data = {'congruent': [], 'incongruent': []}\n",
        "congruent_start_count = 0\n",
        "incongruent_start_count = 0\n",
        "\n",
        "# Initialize dictionaries to store paired data\n",
        "paired_congruent_data = {'congruent': [], 'incongruent': []}\n",
        "paired_incongruent_data = {'congruent': [], 'incongruent': []}\n",
        "\n",
        "# Iterate over each participant's data in the combined DataFrame\n",
        "for subject_id, df in all_participants_df.groupby('Subject ID'):\n",
        "\n",
        "    # Define blocks based on switches in 'Trial type'\n",
        "    df['Block Number'] = (df['Trial type'] != df['Trial type'].shift(1)).cumsum()\n",
        "    df['Block'] = df['Block Number'].astype(str) + df['Trial type'].apply(lambda x: 'C' if x == 'aligned' else 'I')\n",
        "\n",
        "    # Count how many participants started with congruent vs incongruent\n",
        "    first_trial_type = df['Trial type'].iloc[0]\n",
        "    if first_trial_type == 'aligned':\n",
        "        congruent_trials = df[df['Trial type'] == 'aligned']['Correct (Theoretical)'].astype(int).tolist()\n",
        "        incongruent_trials = df[df['Trial type'] == 'unaligned']['Correct (Theoretical)'].astype(int).tolist()\n",
        "        if len(congruent_trials) == len(incongruent_trials):\n",
        "            # Store only if paired data has the same length\n",
        "            paired_congruent_data['congruent'].extend(congruent_trials)\n",
        "            paired_congruent_data['incongruent'].extend(incongruent_trials)\n",
        "        congruent_start_count += 1\n",
        "    else:\n",
        "        congruent_trials = df[df['Trial type'] == 'aligned']['Correct (Theoretical)'].astype(int).tolist()\n",
        "        incongruent_trials = df[df['Trial type'] == 'unaligned']['Correct (Theoretical)'].astype(int).tolist()\n",
        "        if len(congruent_trials) == len(incongruent_trials):\n",
        "            # Store only if paired data has the same length\n",
        "            paired_incongruent_data['congruent'].extend(congruent_trials)\n",
        "            paired_incongruent_data['incongruent'].extend(incongruent_trials)\n",
        "        incongruent_start_count += 1\n",
        "\n",
        "    # Number of trials in each 'Block'\n",
        "    block_counts = df['Block'].value_counts()\n",
        "\n",
        "    # Accuracy in each 'Block'\n",
        "    block_accuracy = df.groupby('Block')['Correct (Theoretical)'].mean()\n",
        "\n",
        "    # Accuracy per 'Trial type' (congruent and incongruent)\n",
        "    df['Correct (Theoretical)'] = df['Correct (Theoretical)'].astype(int)  # Convert to integer\n",
        "\n",
        "    # Accuracy per 'Trial type' (congruent and incongruent)\n",
        "    trial_type_accuracy = df.groupby('Trial type')['Correct (Theoretical)'].mean()\n",
        "\n",
        "    # Accuracy over the whole task\n",
        "    overall_accuracy = df.groupby('Block')['Correct (Theoretical)'].mean()\n",
        "\n",
        "    # Accuracy as a function of 'Image Rating'\n",
        "    # Convert 'Correct (Theoretical)' to binary (1 and 0)\n",
        "    df['Correct (Binary)'] = df['Correct (Theoretical)'].astype(int)\n",
        "\n",
        "    # Create a contingency table\n",
        "    contingency_table = pd.crosstab(df['Image Rating'], df['Correct (Binary)'])\n",
        "\n",
        "    # Perform chi-squared test\n",
        "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "    # Append data to lists\n",
        "    all_block_counts.append(block_counts)\n",
        "    all_block_accuracy.append(block_accuracy)\n",
        "    all_trial_type_accuracy.append(trial_type_accuracy)\n",
        "    all_wilcoxon_p_values_tt.append(p)\n",
        "    all_overall_accuracy.append(overall_accuracy)\n",
        "    all_image_rating_data.append(df.groupby('Image Rating')['Correct (Theoretical)'].mean())\n",
        "    all_chi2_p_values.append(p)\n",
        "\n",
        "# Plotting across participants\n",
        "\n",
        "# Define custom color palette\n",
        "color = 'black'\n",
        "\n",
        "# Accuracy by Block with Error 'Cloud' for Average Accuracy for Congruent and Incongruent Starts\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Separate data for 'Congruent' and 'Incongruent' starts\n",
        "congruent_data = [block_accuracy for block_accuracy in all_block_accuracy if 'C' in block_accuracy.index[0]]\n",
        "incongruent_data = [block_accuracy for block_accuracy in all_block_accuracy if 'I' in block_accuracy.index[0]]\n",
        "\n",
        "# Plot for Congruent starts if there is any data\n",
        "if congruent_data:\n",
        "    for block_accuracy in congruent_data:\n",
        "        plt.plot(block_accuracy.index, block_accuracy, color='LightGrey', alpha=0.3)  # Faint grey lines for individual accuracies\n",
        "\n",
        "    congruent_data_df = pd.concat(congruent_data, axis=1)\n",
        "    avg_congruent_accuracy = congruent_data_df.mean(axis=1)\n",
        "    sem_congruent_accuracy = congruent_data_df.sem(axis=1)  # Standard Error of the Mean (SEM)\n",
        "\n",
        "    plt.errorbar(avg_congruent_accuracy.index, avg_congruent_accuracy, yerr=sem_congruent_accuracy, fmt='o-', color=color, label='Average Congruent-Start Accuracy')\n",
        "\n",
        "# Plot for Incongruent starts if there is any data\n",
        "if incongruent_data:\n",
        "    for block_accuracy in incongruent_data:\n",
        "        plt.plot(block_accuracy.index, block_accuracy, color='LightGrey', alpha=0.3)  # Faint grey lines for individual accuracies\n",
        "\n",
        "    incongruent_data_df = pd.concat(incongruent_data, axis=1)\n",
        "    avg_incongruent_accuracy = incongruent_data_df.mean(axis=1)\n",
        "    sem_incongruent_accuracy = incongruent_data_df.sem(axis=1)  # Standard Error of the Mean (SEM)\n",
        "\n",
        "    plt.errorbar(avg_incongruent_accuracy.index, avg_incongruent_accuracy, yerr=sem_incongruent_accuracy, fmt='o-', color=color, label='Average Incongruent-Start Accuracy')\n",
        "\n",
        "# Adding the dotted dark grey line at 0.5 for chance level\n",
        "plt.axhline(y=0.5, color='darkgrey', linestyle='--', linewidth=1, label='Chance Level')\n",
        "\n",
        "# Only show plot if there is data\n",
        "if congruent_data or incongruent_data:\n",
        "    plt.xlabel('Block', fontsize=18, fontweight='bold', labelpad=15)\n",
        "    plt.ylabel('Average Accuracy', fontsize=18, fontweight='bold', labelpad=15)\n",
        "    plt.xticks(fontsize=16)\n",
        "    plt.yticks(fontsize=16)\n",
        "    plt.title(f'Accuracy by Block (Congruent starts: {congruent_start_count}, Incongruent starts: {incongruent_start_count})')\n",
        "\n",
        "    # Create custom legend entries\n",
        "    from matplotlib.lines import Line2D\n",
        "    legend_elements = [Line2D([0], [0], linestyle='-', color=color, label='Average Congruent-Start Accuracy'),\n",
        "                       Line2D([0], [0], linestyle='-', color=color, label='Average Incongruent-Start Accuracy'),\n",
        "                       Line2D([0], [0], linestyle='--', color='darkgrey', label='Chance Level')]\n",
        "\n",
        "    plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5), frameon=False)  # frameon=False for no box\n",
        "\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No data available for congruent or incongruent starts.\")\n",
        "\n",
        "# Initialize lists to store mean accuracy for each participant based on their start type\n",
        "congruent_start_accuracies_list = []\n",
        "incongruent_start_accuracies_list = []\n",
        "\n",
        "# Iterate over each participant's data\n",
        "for subject_id, df in all_participants_df.groupby('Subject ID'):\n",
        "\n",
        "    # Define blocks based on switches in 'Trial type'\n",
        "    df['Block Number'] = (df['Trial type'] != df['Trial type'].shift(1)).cumsum()\n",
        "    df['Block'] = df['Block Number'].astype(str) + df['Trial type'].apply(lambda x: 'C' if x == 'aligned' else 'I')\n",
        "\n",
        "    # Calculate mean accuracy across all blocks for this participant\n",
        "    mean_accuracy = df['Correct (Theoretical)'].mean()\n",
        "\n",
        "    # Determine if this participant started with congruent or incongruent\n",
        "    first_trial_type = df['Trial type'].iloc[0]\n",
        "\n",
        "    # Append mean accuracy to the corresponding list\n",
        "    if first_trial_type == 'aligned':\n",
        "        congruent_start_accuracies_list.append(mean_accuracy)\n",
        "    else:\n",
        "        incongruent_start_accuracies_list.append(mean_accuracy)\n",
        "\n",
        "# Initialize lists to store results\n",
        "significant_blocks_congruent = []\n",
        "significant_blocks_incongruent = []\n",
        "\n",
        "# Wilcoxon Signed-Rank Test for congruent data\n",
        "if congruent_data:\n",
        "    for block in avg_congruent_accuracy.index:\n",
        "        block_values = np.array([block_acc.loc[block] for block_acc in congruent_data if block in block_acc.index])\n",
        "        # Ensure at least 2 data points for Wilcoxon test\n",
        "        if len(block_values) > 1:\n",
        "            stat, p_value = wilcoxon(block_values - 0.5)\n",
        "            if p_value < 0.05:\n",
        "                significant_blocks_congruent.append((block, stat, p_value))\n",
        "\n",
        "# Wilcoxon Signed-Rank Test for incongruent data\n",
        "if incongruent_data:\n",
        "    for block in avg_incongruent_accuracy.index:\n",
        "        block_values = np.array([block_acc.loc[block] for block_acc in incongruent_data if block in block_acc.index])\n",
        "        # Ensure at least 2 data points for Wilcoxon test\n",
        "        if len(block_values) > 1:\n",
        "            stat, p_value = wilcoxon(block_values - 0.5)\n",
        "            if p_value < 0.05:\n",
        "                significant_blocks_incongruent.append((block, stat, p_value))\n",
        "\n",
        "# Print out the results\n",
        "print(\"Significant blocks for congruent start participants (accuracy significantly above 0.5):\")\n",
        "for block, stat, p_value in significant_blocks_congruent:\n",
        "    print(f\"Block {block}: Wilcoxon stat = {stat:.3f}, p-value = {p_value:.6f}\")\n",
        "\n",
        "print(\"\\nSignificant blocks for incongruent start participants (accuracy significantly above 0.5):\")\n",
        "for block, stat, p_value in significant_blocks_incongruent:\n",
        "    print(f\"Block {block}: Wilcoxon stat = {stat:.3f}, p-value = {p_value:.6f}\")\n",
        "\n",
        "# Wilcoxon Signed-Rank Test: Compare congruent vs incongruent blocks within starting groups\n",
        "# Congruent start subjects\n",
        "if len(paired_congruent_data['congruent']) > 0 and len(paired_congruent_data['incongruent']) > 0:\n",
        "    stat, p_value = wilcoxon(paired_congruent_data['congruent'], paired_congruent_data['incongruent'])\n",
        "    print(f'Congruent start subjects: Wilcoxon Signed-Rank Test between Congruent and Incongruent blocks: stat={stat}, p-value={p_value}')\n",
        "\n",
        "# Incongruent start subjects\n",
        "if len(paired_incongruent_data['congruent']) > 0 and len(paired_incongruent_data['incongruent']) > 0:\n",
        "    stat, p_value = wilcoxon(paired_incongruent_data['congruent'], paired_incongruent_data['incongruent'])\n",
        "    print(f'Incongruent start subjects: Wilcoxon Signed-Rank Test between Congruent and Incongruent blocks: stat={stat}, p-value={p_value}')"
      ],
      "metadata": {
        "id": "0TE4wboaYA97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import mannwhitneyu, norm, levene\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume all_participants_df is defined and contains the data.\n",
        "\n",
        "# Extract data for the Mann-Whitney U test\n",
        "aligned_start_aligned_accuracy = []\n",
        "unaligned_start_aligned_accuracy = []\n",
        "aligned_start_unaligned_accuracy = []\n",
        "unaligned_start_unaligned_accuracy = []\n",
        "\n",
        "for subject_id, df in all_participants_df.groupby('Subject ID'):\n",
        "    first_trial_type = df['Trial type'].iloc[0]\n",
        "    aligned_accuracy = df[df['Trial type'] == 'aligned']['Correct (Theoretical)'].mean()\n",
        "    unaligned_accuracy = df[df['Trial type'] == 'unaligned']['Correct (Theoretical)'].mean()\n",
        "\n",
        "    if first_trial_type == 'aligned':\n",
        "        aligned_start_aligned_accuracy.append(aligned_accuracy)\n",
        "        aligned_start_unaligned_accuracy.append(unaligned_accuracy)\n",
        "    else:\n",
        "        unaligned_start_aligned_accuracy.append(aligned_accuracy)\n",
        "        unaligned_start_unaligned_accuracy.append(unaligned_accuracy)\n",
        "\n",
        "def mannwhitneyu_report(x, y, confidence_level=0.95):\n",
        "    u_statistic, p_value = mannwhitneyu(x, y, alternative='two-sided')\n",
        "    n1, n2 = len(x), len(y)\n",
        "\n",
        "    # Calculating z-statistic\n",
        "    u_mean = n1 * n2 / 2\n",
        "    u_std = np.sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)\n",
        "    z_statistic = (u_statistic - u_mean) / u_std\n",
        "\n",
        "    # Calculate effect size (R)\n",
        "    effect_size = z_statistic / np.sqrt(n1 + n2)\n",
        "\n",
        "    # Calculate mean and std of U distribution\n",
        "    u_mean = n1 * n2 / 2\n",
        "    u_std = np.sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)\n",
        "\n",
        "    # Calculate z-value for the given confidence interval\n",
        "    z = norm.ppf(1 - (1 - confidence_level) / 2)\n",
        "\n",
        "    # Calculate confidence interval\n",
        "    ci_lower = u_mean - z * u_std\n",
        "    ci_upper = u_mean + z * u_std\n",
        "\n",
        "    # Means and standard deviations\n",
        "    mean_x = np.mean(x)\n",
        "    mean_y = np.mean(y)\n",
        "    std_x = np.std(x, ddof=1)\n",
        "    std_y = np.std(y, ddof=1)\n",
        "\n",
        "    return {\n",
        "        'u_statistic': u_statistic,\n",
        "        'p_value': p_value,\n",
        "        'n1': n1,\n",
        "        'n2': n2,\n",
        "        'z_statistic': z_statistic,\n",
        "        'effect_size': effect_size,\n",
        "        'mean_x': mean_x,\n",
        "        'mean_y': mean_y,\n",
        "        'std_x': std_x,\n",
        "        'std_y': std_y,\n",
        "        'ci_lower': ci_lower,\n",
        "        'ci_upper': ci_upper\n",
        "    }\n",
        "\n",
        "# Mann-Whitney U test for aligned trial type accuracy between aligned-start and unaligned-start groups\n",
        "report_aligned = mannwhitneyu_report(aligned_start_aligned_accuracy, unaligned_start_aligned_accuracy)\n",
        "\n",
        "# Mann-Whitney U test for unaligned trial type accuracy between aligned-start and unaligned-start groups\n",
        "report_unaligned = mannwhitneyu_report(aligned_start_unaligned_accuracy, unaligned_start_unaligned_accuracy)\n",
        "\n",
        "# Means and standard deviations for each group\n",
        "mean_aligned_start_aligned = np.mean(aligned_start_aligned_accuracy)\n",
        "std_aligned_start_aligned = np.std(aligned_start_aligned_accuracy, ddof=1)\n",
        "mean_unaligned_start_aligned = np.mean(unaligned_start_aligned_accuracy)\n",
        "std_unaligned_start_aligned = np.std(unaligned_start_aligned_accuracy, ddof=1)\n",
        "mean_aligned_start_unaligned = np.mean(aligned_start_unaligned_accuracy)\n",
        "std_aligned_start_unaligned = np.std(aligned_start_unaligned_accuracy, ddof=1)\n",
        "mean_unaligned_start_unaligned = np.mean(unaligned_start_unaligned_accuracy)\n",
        "std_unaligned_start_unaligned = np.std(unaligned_start_unaligned_accuracy, ddof=1)\n",
        "\n",
        "print(f\"Mean accuracy for aligned trial type in aligned-start group: {mean_aligned_start_aligned:.3f} ± {std_aligned_start_aligned:.3f}\")\n",
        "print(f\"Mean accuracy for aligned trial type in unaligned-start group: {mean_unaligned_start_aligned:.3f} ± {std_unaligned_start_aligned:.3f}\")\n",
        "print(f\"Mean accuracy for unaligned trial type in aligned-start group: {mean_aligned_start_unaligned:.3f} ± {std_aligned_start_unaligned:.3f}\")\n",
        "print(f\"Mean accuracy for unaligned trial type in unaligned-start group: {mean_unaligned_start_unaligned:.3f} ± {std_unaligned_start_unaligned:.3f}\")\n",
        "\n",
        "# Print detailed results for aligned trial type\n",
        "print(f\"Mann-Whitney U test for aligned trial type accuracy between groups:\")\n",
        "print(f\"U-statistic = {report_aligned['u_statistic']:.3f}, p-value = {report_aligned['p_value']:.6f}\")\n",
        "print(f\"Sample sizes: N1 = {report_aligned['n1']}, N2 = {report_aligned['n2']}\")\n",
        "print(f\"Z-statistic = {report_aligned['z_statistic']:.3f}\")\n",
        "print(f\"Effect size (R) = {report_aligned['effect_size']:.3f}\")\n",
        "print(f\"Means: Aligned start = {report_aligned['mean_x']:.3f} ± {report_aligned['std_x']:.3f}, Unaligned start = {report_aligned['mean_y']:.3f} ± {report_aligned['std_y']:.3f}\")\n",
        "print(f\"95% Confidence Interval for U: ({report_aligned['ci_lower']:.3f}, {report_aligned['ci_upper']:.3f})\")\n",
        "\n",
        "# Print detailed results for unaligned trial type\n",
        "print(f\"\\nMann-Whitney U test for unaligned trial type accuracy between groups:\")\n",
        "print(f\"U-statistic = {report_unaligned['u_statistic']:.3f}, p-value = {report_unaligned['p_value']:.6f}\")\n",
        "print(f\"Sample sizes: N1 = {report_unaligned['n1']}, N2 = {report_unaligned['n2']}\")\n",
        "print(f\"Z-statistic = {report_unaligned['z_statistic']:.3f}\")\n",
        "print(f\"Effect size (R) = {report_unaligned['effect_size']:.3f}\")\n",
        "print(f\"Means: Aligned start = {report_unaligned['mean_x']:.3f} ± {report_unaligned['std_x']:.3f}, Unaligned start = {report_unaligned['mean_y']:.3f} ± {report_unaligned['std_y']:.3f}\")\n",
        "print(f\"95% Confidence Interval for U: ({report_unaligned['ci_lower']:.3f}, {report_unaligned['ci_upper']:.3f})\")\n",
        "\n",
        "# Compute overall mean accuracy for each group (including both trial types)\n",
        "overall_accuracy_aligned_start = aligned_start_aligned_accuracy + aligned_start_unaligned_accuracy\n",
        "overall_accuracy_unaligned_start = unaligned_start_aligned_accuracy + unaligned_start_unaligned_accuracy\n",
        "\n",
        "# Per-subject average accuracy\n",
        "aligned_subjects_overall = [np.mean([aligned, unaligned]) for aligned, unaligned in zip(aligned_start_aligned_accuracy, aligned_start_unaligned_accuracy)]\n",
        "unaligned_subjects_overall = [np.mean([aligned, unaligned]) for aligned, unaligned in zip(unaligned_start_aligned_accuracy, unaligned_start_unaligned_accuracy)]\n",
        "\n",
        "# Means and standard deviations for overall accuracy\n",
        "mean_overall_aligned_start = np.mean(aligned_subjects_overall)\n",
        "std_overall_aligned_start = np.std(aligned_subjects_overall, ddof=1)\n",
        "mean_overall_unaligned_start = np.mean(unaligned_subjects_overall)\n",
        "std_overall_unaligned_start = np.std(unaligned_subjects_overall, ddof=1)\n",
        "\n",
        "# Perform Mann-Whitney U test for overall accuracy between aligned-start and unaligned-start groups\n",
        "report_overall = mannwhitneyu_report(aligned_subjects_overall, unaligned_subjects_overall)\n",
        "\n",
        "print(f\"\\nOverall mean accuracy for aligned-start group: {mean_overall_aligned_start:.3f} ± {std_overall_aligned_start:.3f}\")\n",
        "print(f\"Overall mean accuracy for unaligned-start group: {mean_overall_unaligned_start:.3f} ± {std_overall_unaligned_start:.3f}\")\n",
        "\n",
        "# Print detailed results for overall accuracy\n",
        "print(f\"Mann-Whitney U test for overall accuracy between starting groups:\")\n",
        "print(f\"U-statistic = {report_overall['u_statistic']:.3f}, p-value = {report_overall['p_value']:.6f}\")\n",
        "print(f\"Sample sizes: N1 = {report_overall['n1']}, N2 = {report_overall['n2']}\")\n",
        "print(f\"Z-statistic = {report_overall['z_statistic']:.3f}\")\n",
        "print(f\"Effect size (R) = {report_overall['effect_size']:.3f}\")\n",
        "print(f\"Means: Aligned start = {report_overall['mean_x']:.3f} ± {report_overall['std_x']:.3f}, Unaligned start = {report_overall['mean_y']:.3f} ± {report_overall['std_y']:.3f}\")\n",
        "print(f\"95% Confidence Interval for U: ({report_overall['ci_lower']:.3f}, {report_overall['ci_upper']:.3f})\")\n",
        "\n",
        "# Extract accuracies for all aligned and unaligned trials irrespective of starting type\n",
        "all_aligned_accuracies = aligned_start_aligned_accuracy + unaligned_start_aligned_accuracy\n",
        "all_unaligned_accuracies = aligned_start_unaligned_accuracy + unaligned_start_unaligned_accuracy\n",
        "\n",
        "# Mann-Whitney U test for aligned vs. unaligned trial type accuracy\n",
        "report_all = mannwhitneyu_report(all_aligned_accuracies, all_unaligned_accuracies)\n",
        "\n",
        "# Print detailed results for aligned vs. unaligned trial type\n",
        "print(f\"\\nMann-Whitney U test for aligned vs. unaligned trial type accuracy:\")\n",
        "print(f\"U-statistic = {report_all['u_statistic']:.3f}, p-value = {report_all['p_value']:.6f}\")\n",
        "print(f\"Sample sizes: N1 = {report_all['n1']}, N2 = {report_all['n2']}\")\n",
        "print(f\"Z-statistic = {report_all['z_statistic']:.3f}\")\n",
        "print(f\"Effect size (R) = {report_all['effect_size']:.3f}\")\n",
        "print(f\"Means: Aligned = {report_all['mean_x']:.3f} ± {report_all['std_x']:.3f}, Unaligned = {report_all['mean_y']:.3f} ± {report_all['std_y']:.3f}\")\n",
        "print(f\"95% Confidence Interval for U: ({report_all['ci_lower']:.3f}, {report_all['ci_upper']:.3f})\")\n",
        "\n",
        "# Preparing data for 2x2 ANOVA\n",
        "anova_data = {\n",
        "    'Start_Type': [],\n",
        "    'Trial_Type': [],\n",
        "    'Accuracy': []\n",
        "}\n",
        "\n",
        "for subject_id, df in all_participants_df.groupby('Subject ID'):\n",
        "    first_trial_type = df['Trial type'].iloc[0]\n",
        "    start_type = 'Aligned' if first_trial_type == 'aligned' else 'Unaligned'\n",
        "    for trial_type, sub_df in df.groupby('Trial type'):\n",
        "        average_accuracy = sub_df['Correct (Theoretical)'].mean()\n",
        "        trial_label = 'Aligned_Trial_Type' if trial_type == 'aligned' else 'Unaligned_Trial_Type'\n",
        "        anova_data['Start_Type'].append(start_type)\n",
        "        anova_data['Trial_Type'].append(trial_label)\n",
        "        anova_data['Accuracy'].append(average_accuracy)\n",
        "\n",
        "anova_df = pd.DataFrame(anova_data)\n",
        "\n",
        "# 2x2 ANOVA\n",
        "model = ols('Accuracy ~ C(Start_Type) * C(Trial_Type)', data=anova_df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Extracting degrees of freedom\n",
        "df_start_type = anova_table.loc['C(Start_Type)', 'df']\n",
        "df_trial_type = anova_table.loc['C(Trial_Type)', 'df']\n",
        "df_interaction = anova_table.loc['C(Start_Type):C(Trial_Type)', 'df']\n",
        "df_residual = anova_table.loc['Residual', 'df']\n",
        "\n",
        "df_between = df_start_type + df_trial_type + df_interaction\n",
        "df_within = df_residual\n",
        "\n",
        "print(anova_table)\n",
        "print(\"\\nDegrees of Freedom:\")\n",
        "print(f\"Between Groups: {df_between}\")\n",
        "print(f\"Within Groups: {df_within}\")\n",
        "\n",
        "# Tukey's HSD post hoc analysis\n",
        "mc = pairwise_tukeyhsd(anova_df['Accuracy'], anova_df['Start_Type'] + \"_\" + anova_df['Trial_Type'], alpha=0.05)\n",
        "print(mc)\n",
        "\n",
        "# Perform Levene's test for homogeneity of variances\n",
        "stat, p = levene(anova_df[anova_df['Start_Type'] == 'Aligned']['Accuracy'],\n",
        "                 anova_df[anova_df['Start_Type'] == 'Unaligned']['Accuracy'],\n",
        "                 anova_df[anova_df['Trial_Type'] == 'Aligned_Trial_Type']['Accuracy'],\n",
        "                 anova_df[anova_df['Trial_Type'] == 'Unaligned_Trial_Type']['Accuracy'])\n",
        "# Calculate degrees of freedom for Levene's test\n",
        "df_group = 3  # Number of groups - 1\n",
        "df_total = len(anova_df['Accuracy']) - 4  # Total number of observations - number of groups\n",
        "\n",
        "print(f\"Levene's Test for homogeneity of variances: F({df_group}, {df_total}) = {stat:.2f}, p = {p:.3f}\")\n",
        "\n",
        "# Plotting histograms\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(overall_accuracy_aligned_start, bins=20, alpha=0.7, label='Aligned Start')\n",
        "plt.hist(overall_accuracy_unaligned_start, bins=20, alpha=0.7, label='Unaligned Start')\n",
        "plt.title('Histogram of Overall Accuracies')\n",
        "plt.legend()\n",
        "plt.xlabel('Overall Accuracy')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Plotting boxplots\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.boxplot([overall_accuracy_aligned_start, overall_accuracy_unaligned_start], labels=['Aligned Start', 'Unaligned Start'])\n",
        "plt.title('Boxplot of Overall Accuracies')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AwVeK4Z6YDLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average accuracy per block as a function of block type (separated by starting group)\n"
      ],
      "metadata": {
        "id": "0Hi6gOvEYD0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import fligner\n",
        "from itertools import combinations\n",
        "\n",
        "def analyze_and_plot_violin_anova(data_df_aligned, data_df_unaligned):\n",
        "    if data_df_aligned.empty or data_df_unaligned.empty:\n",
        "        print(\"No data available for analysis.\")\n",
        "        return\n",
        "\n",
        "    # Combine data for aligned and unaligned participants\n",
        "    data_df_aligned['Group'] = 'C-start'\n",
        "    data_df_unaligned['Group'] = 'I-start'\n",
        "    combined_data_df = pd.concat([data_df_aligned, data_df_unaligned])\n",
        "\n",
        "    # Calculate mean accuracy per participant for 'Trial type' and 'Group'\n",
        "    mean_combinations = combined_data_df.groupby(['Subject ID', 'Trial type', 'Group'])['Correct (Theoretical)'].mean().reset_index()\n",
        "    mean_combinations['Trial type'] = mean_combinations['Trial type'].replace({'aligned': 'Congruent', 'unaligned': 'Incongruent'})\n",
        "\n",
        "    # Define the custom labels for plotting\n",
        "    mean_combinations['Combined_label'] = mean_combinations.apply(\n",
        "        lambda x: f\"{x['Group']} {x['Trial type']} Trials\", axis=1)\n",
        "\n",
        "    # Conduct ANOVA\n",
        "    formula = 'Q(\"Correct (Theoretical)\") ~ Q(\"Trial type\") * Group'\n",
        "    model = ols(formula, data=mean_combinations).fit()\n",
        "    anova_results = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "    # Conduct post hoc test (Tukey's HSD)\n",
        "    posthoc = pairwise_tukeyhsd(mean_combinations['Correct (Theoretical)'], mean_combinations['Combined_label'])\n",
        "    # Convert Tukey's HSD results to a DataFrame\n",
        "    posthoc_result = pd.DataFrame(data=posthoc.summary().data[1:], columns=posthoc.summary().data[0])\n",
        "\n",
        "    # Format p-values for better readability\n",
        "    posthoc_result[\"p-adj\"] = posthoc_result[\"p-adj\"].apply(lambda p: f\"{p:.2e}\" if p < 0.001 else f\"{p:.3f}\")\n",
        "\n",
        "    # Print the ANOVA results\n",
        "    print(\"\\nANOVA results:\")\n",
        "    print(anova_results)\n",
        "\n",
        "    # Print the updated Tukey's HSD results\n",
        "    print(\"\\nPost hoc test results (Tukey's HSD):\")\n",
        "    print(posthoc_result.to_string(index=False))\n",
        "\n",
        "    # Conduct Fligner-Killeen test for equality of variances\n",
        "    grouped_data = mean_combinations.groupby('Combined_label')['Correct (Theoretical)'].apply(list)\n",
        "    pairwise_results = []\n",
        "\n",
        "    for (group1, data1), (group2, data2) in combinations(zip(grouped_data.index.tolist(), grouped_data), 2):\n",
        "        fligner_pair = fligner(data1, data2)\n",
        "        pairwise_results.append({\n",
        "            'Group1': group1,\n",
        "            'Group2': group2,\n",
        "            'Fligner_statistic': fligner_pair.statistic,\n",
        "            'Fligner_df': len(data1) + len(data2) - 2,\n",
        "            'Fligner_pvalue': fligner_pair.pvalue\n",
        "        })\n",
        "\n",
        "    pairwise_df = pd.DataFrame(pairwise_results)\n",
        "    # Apply Bonferroni correction for multiple comparisons\n",
        "    pairwise_df['Fligner_padj'] = pairwise_df['Fligner_pvalue'] * len(pairwise_results)\n",
        "    pairwise_df['Fligner_padj'] = pairwise_df['Fligner_padj'].apply(lambda p: min(p, 1.0))  # p-value cannot exceed 1.0\n",
        "\n",
        "    # Print pairwise Fligner-Killeen test results\n",
        "    print(\"\\nPairwise Fligner-Killeen test results:\")\n",
        "    print(pairwise_df[['Group1', 'Group2', 'Fligner_statistic', 'Fligner_df', 'Fligner_pvalue']].to_string(index=False))\n",
        "\n",
        "    # Define the custom color palette with specific blue colors\n",
        "    coolwarm_palette = sns.color_palette(\"coolwarm\", 7)\n",
        "    trial_palette = {\n",
        "        'Congruent': coolwarm_palette[0],   # Dark blue\n",
        "        'Incongruent': coolwarm_palette[2]  # Light blue\n",
        "    }\n",
        "\n",
        "    # Adjust labels for grouping by 'Starting block'\n",
        "    mean_combinations['Starting_block'] = mean_combinations['Group']\n",
        "\n",
        "    # Update tick label names\n",
        "    tick_names = {\n",
        "        'C-start': 'Congruent-start',\n",
        "        'I-start': 'Incongruent-start'\n",
        "    }\n",
        "    mean_combinations['Starting_block'] = mean_combinations['Starting_block'].map(tick_names)\n",
        "\n",
        "    # Sort data to ensure 'Congruent-start' is plotted first\n",
        "    mean_combinations['Starting_block'] = pd.Categorical(mean_combinations['Starting_block'], categories=['Congruent-start', 'Incongruent-start'], ordered=True)\n",
        "\n",
        "    # Create figure and plot violin plot\n",
        "    plt.figure(figsize=(18, 8))\n",
        "    base_positions = {'Congruent-start': 0, 'Incongruent-start': 1}\n",
        "    sns.violinplot(x='Starting_block', y='Correct (Theoretical)', hue='Trial type', data=mean_combinations,\n",
        "                   palette=trial_palette, split=False, inner=None, dodge=True)\n",
        "    sns.stripplot(x='Starting_block', y='Correct (Theoretical)', hue='Trial type', data=mean_combinations,\n",
        "                  jitter=True, color='black', alpha=0.6, dodge=True)\n",
        "\n",
        "    # Overlay means and IQRs\n",
        "    offsets = {'Congruent': -0.2, 'Incongruent': 0.2}  # Adjusting offsets for better alignment\n",
        "    for starting_block in mean_combinations['Starting_block'].unique():\n",
        "        for trial_type in mean_combinations['Trial type'].unique():\n",
        "            subset = mean_combinations[(mean_combinations['Starting_block'] == starting_block) &\n",
        "                                       (mean_combinations['Trial type'] == trial_type)]\n",
        "            base_position = base_positions[starting_block]\n",
        "            xpos = base_position + offsets[trial_type]\n",
        "\n",
        "            mean_val = subset['Correct (Theoretical)'].mean()\n",
        "            q25, q75 = subset['Correct (Theoretical)'].quantile([0.25, 0.75])\n",
        "\n",
        "            # Plotting mean and IQR\n",
        "            plt.scatter(x=[xpos], y=[mean_val], color='lightgray', s=20, zorder=3)\n",
        "            plt.plot([xpos, xpos], [q25, q75], color='gray', lw=3, solid_capstyle='butt', zorder=2)\n",
        "\n",
        "    plt.xlabel('Starting block', fontsize=24, fontweight='bold')\n",
        "    plt.ylabel('Average Accuracy', fontsize=24, fontweight='bold')\n",
        "    plt.title('Average Accuracy by Condition (Combined Group and Trial Type)', fontsize=26, pad=20)\n",
        "    plt.xticks([0, 1], ['Congruent-start', 'Incongruent-start'], fontsize=20)\n",
        "    plt.yticks(np.linspace(0, 1, 6), fontsize=18)  # y-ticks from 0 to 1 in 0.2 increments\n",
        "\n",
        "    # Expand the y-axis limit to create space for annotations\n",
        "    plt.ylim(0, 1.2)  # Extend beyond 1.0 for space for annotation\n",
        "\n",
        "    # Handle legend properly\n",
        "    handles, labels = plt.gca().get_legend_handles_labels()\n",
        "    unique_labels = dict(zip(labels, handles))\n",
        "\n",
        "    # Update the legend to have the desired labels\n",
        "    correct_labels = ['Congruent', 'Incongruent']\n",
        "    plt.legend(handles[:2], correct_labels, title='Trial type', fontsize=20, title_fontsize=19)\n",
        "\n",
        "    sns.despine()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the Fligner-Killeen test results in APA style\n",
        "    for index, row in pairwise_df.iterrows():\n",
        "        print(f\"For the comparison between {row['Group1']} and {row['Group2']}: X²({row['Fligner_df']}) = {row['Fligner_statistic']:.2f}, p = {row['Fligner_pvalue']:.3f}\")\n",
        "\n",
        "analyze_and_plot_violin_anova(aligned_start_df, unaligned_start_df)"
      ],
      "metadata": {
        "id": "QDUI3L05YOEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Average trialwise accuracy within each block, by starting group"
      ],
      "metadata": {
        "id": "Y1iDGe_FYPVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming all_participants_df has been prepared with correct block numbers and trial numbers.\n",
        "\n",
        "# Define a function to fix block numbering for each participant\n",
        "def fix_block_numbering(df):\n",
        "    participants = df['Subject ID'].unique()\n",
        "    fixed_df_list = []\n",
        "\n",
        "    for participant in participants:\n",
        "        participant_df = df[df['Subject ID'] == participant].copy()\n",
        "        participant_df['Block Number'] = (participant_df['Trial type'] != participant_df['Trial type'].shift(1)).cumsum()\n",
        "        participant_df['Block'] = participant_df['Block Number'].astype(str) + \\\n",
        "                                  participant_df['Trial type'].apply(lambda x: 'A' if x == 'aligned' else 'U')\n",
        "        fixed_df_list.append(participant_df)\n",
        "\n",
        "    fixed_df = pd.concat(fixed_df_list, ignore_index=True)\n",
        "    return fixed_df\n",
        "\n",
        "# Apply the fix\n",
        "all_participants_df = fix_block_numbering(all_participants_df)\n",
        "\n",
        "# Add cumulative trial number within each block\n",
        "all_participants_df['Trial Number'] = all_participants_df.groupby(['Subject ID', 'Block'])['Trial type'].cumcount() + 1\n",
        "\n",
        "# Convert 'Correct (Theoretical)' to binary (1 for True, 0 for False)\n",
        "all_participants_df['Correct (Binary)'] = all_participants_df['Correct (Theoretical)'].astype(int)\n",
        "\n",
        "# Convert 'Block' to string and create a column to represent the type of block (Congruent/Incongruent)\n",
        "all_participants_df['Block Type'] = all_participants_df['Trial type'].apply(lambda x: 'Congruent' if x == 'aligned' else 'Incongruent')\n",
        "\n",
        "# Separate data based on the starting block type\n",
        "aligned_start_df = all_participants_df.groupby('Subject ID').filter(lambda x: x['Trial type'].iloc[0] == 'aligned')\n",
        "unaligned_start_df = all_participants_df.groupby('Subject ID').filter(lambda x: x['Trial type'].iloc[0] == 'unaligned')\n",
        "\n",
        "# Count the number of unique participants in each subset\n",
        "aligned_start_participants = aligned_start_df['Subject ID'].nunique()\n",
        "unaligned_start_participants = unaligned_start_df['Subject ID'].nunique()\n",
        "\n",
        "# Define the coolwarm palette and extract colors\n",
        "coolwarm_palette = sns.color_palette(\"coolwarm\")\n",
        "palette = {'Congruent': coolwarm_palette[0], 'Incongruent': coolwarm_palette[1]}  # Switching colors\n",
        "\n",
        "# Function to analyze and plot data for a given subset with specified colors for each trial type\n",
        "def analyze_and_plot_combined(data_df, start_type, num_participants):\n",
        "    blocks = data_df['Block Number'].unique()\n",
        "    max_aligned_trials = 36  # Adjust if needed\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(18, 6))\n",
        "\n",
        "    for block in blocks:\n",
        "        block_data = data_df[data_df['Block Number'] == block]\n",
        "        overall_avg = block_data.groupby(['Trial Number'])['Correct (Theoretical)'].agg(['mean', 'sem']).reset_index()\n",
        "\n",
        "        # Filter out trials that exceed the maximum\n",
        "        overall_avg_filtered = overall_avg[overall_avg['Trial Number'] <= max_aligned_trials]\n",
        "\n",
        "        # Determine the block type for color assignment\n",
        "        block_type = block_data['Block Type'].iloc[0]\n",
        "\n",
        "        # Plot overall average accuracy per trial for each block with error bands\n",
        "        sns.lineplot(x=overall_avg_filtered['Trial Number'] + (block - 1) * max_aligned_trials,\n",
        "                     y=overall_avg_filtered['mean'],\n",
        "                     color=palette[block_type],\n",
        "                     ax=ax, marker='o',\n",
        "                     label=f'Block {block} ({block_type})',\n",
        "                     errorbar=None)\n",
        "\n",
        "        # Draw the error bands manually\n",
        "        ax.fill_between(overall_avg_filtered['Trial Number'] + (block - 1) * max_aligned_trials,\n",
        "                        overall_avg_filtered['mean'] - overall_avg_filtered['sem'],\n",
        "                        overall_avg_filtered['mean'] + overall_avg_filtered['sem'],\n",
        "                        color=palette[block_type], alpha=0.2)\n",
        "\n",
        "        # Vertical line to indicate block change\n",
        "        if block < blocks[-1]:\n",
        "            ax.axvline(x=block * max_aligned_trials, linestyle='--', color='grey')\n",
        "\n",
        "    # Adding titles and labels with increased font size\n",
        "    ax.set_title(f'Average Accuracy Over Time Within Blocks 1-6 (by trial) - Start Type: {start_type}\\n(N = {num_participants} participants)', fontsize=20)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.axhline(0.5, linestyle='--', color='grey', label='Chance Level')\n",
        "    ax.set_xlabel('Trial Number', fontsize=18, fontweight='bold')\n",
        "    ax.set_ylabel('Average Accuracy', fontsize=18, fontweight='bold')\n",
        "    plt.xticks(ticks=[i * max_aligned_trials for i in range(len(blocks))], fontsize=16)\n",
        "    plt.yticks(fontsize=16)\n",
        "\n",
        "    # Creating a custom legend\n",
        "    custom_legend = [plt.Line2D([0], [0], color=palette['Congruent'], lw=2, label='Congruent'),\n",
        "                     plt.Line2D([0], [0], color=palette['Incongruent'], lw=2, label='Incongruent'),\n",
        "                     plt.Line2D([0], [0], linestyle='--', color='grey', lw=2, label='Chance Level')]\n",
        "    ax.legend(handles=custom_legend, title='Trial Type', fontsize=16, title_fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "\n",
        "# Analyze and plot for aligned-start participants\n",
        "analyze_and_plot_combined(aligned_start_df, 'Congruent Start', aligned_start_participants)\n",
        "\n",
        "# Analyze and plot for unaligned-start participants\n",
        "analyze_and_plot_combined(unaligned_start_df, 'Incongruent Start', unaligned_start_participants)"
      ],
      "metadata": {
        "id": "TTUtgsLmYSJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy as a function of reward (+5) v.s. punishment (-5) associated conditions\n"
      ],
      "metadata": {
        "id": "uV9QrRS-YWXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import mannwhitneyu\n",
        "import pandas as pd\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.lines import Line2D  # Import Line2D for custom legend line\n",
        "\n",
        "# Define the new color palette for better compatibility with orange and purple\n",
        "new_palette = ['#b2d8d8', '#ffcccb']\n",
        "\n",
        "# Manually defining the color palette for each combination\n",
        "custom_palette = {\n",
        "    ('Congruent', 'Liked items'): new_palette[0],  # +5 outcome in Congruent block\n",
        "    ('Congruent', 'Disliked items'): new_palette[1],  # -5 outcome in Congruent block\n",
        "    ('Incongruent', 'Liked items'): new_palette[1],  # -5 outcome in Incongruent block\n",
        "    ('Incongruent', 'Disliked items'): new_palette[0]  # +5 outcome in Incongruent block\n",
        "}\n",
        "\n",
        "# Define a function to print and plot accuracy by block and image rating for each group with significance\n",
        "def plot_accuracy_by_block_image_rating(data_df, title_suffix):\n",
        "    if data_df.empty:\n",
        "        print(f\"No data to plot for {title_suffix}.\")\n",
        "        return\n",
        "\n",
        "    # Combine 'like' and 'strongly like' into 'Liked items', and 'dislike' and 'strongly dislike' into 'Disliked items'\n",
        "    data_df['Image Rating'] = data_df['Image Rating'].replace({\n",
        "        'like': 'Liked items',\n",
        "        'strongly_like': 'Liked items',\n",
        "        'dislike': 'Disliked items',\n",
        "        'strongly_dislike': 'Disliked items'\n",
        "    })\n",
        "\n",
        "    # Replace 'Aligned' with 'Congruent' and 'Unaligned' with 'Incongruent' in 'Block Type'\n",
        "    data_df['Block Type'] = data_df['Block Type'].replace({\n",
        "        'Aligned': 'Congruent',\n",
        "        'Unaligned': 'Incongruent'\n",
        "    })\n",
        "\n",
        "    # Ensure 'Image Rating' is in the specified order\n",
        "    rating_order = ['Disliked items', 'Liked items']\n",
        "    data_df['Image Rating'] = pd.Categorical(data_df['Image Rating'], categories=rating_order, ordered=True)\n",
        "\n",
        "    # Ensure 'Block Type' is in the specified order\n",
        "    block_order = ['Congruent', 'Incongruent']\n",
        "    data_df['Block Type'] = pd.Categorical(data_df['Block Type'], categories=block_order, ordered=True)\n",
        "\n",
        "    # Compute the average accuracy for each participant by Block Type and Image Rating\n",
        "    participant_means = data_df.groupby(['Subject ID', 'Block Type', 'Image Rating'], observed=False)['Correct (Binary)'].mean().reset_index()\n",
        "\n",
        "    # Create a DataFrame for significance testing\n",
        "    comparisons = []\n",
        "    for block in block_order:\n",
        "        rating1, rating2 = rating_order\n",
        "        liked_data = data_df[(data_df['Block Type'] == block) & (data_df['Image Rating'] == 'Liked items')]['Correct (Binary)']\n",
        "        disliked_data = data_df[(data_df['Block Type'] == block) & (data_df['Image Rating'] == 'Disliked items')]['Correct (Binary)']\n",
        "        stat, p_value = mannwhitneyu(liked_data, disliked_data, alternative='two-sided')\n",
        "        comparisons.append((block, rating1, rating2, stat, p_value))\n",
        "        if p_value < 0.001:\n",
        "            print(f\"Accuracy for '{rating1}' is significantly different from '{rating2}' in {block} block (p<.001).\")\n",
        "        else:\n",
        "            print(f\"Accuracy for '{rating1}' is not significantly different from '{rating2}' in {block} block (p = {p_value:.3f}).\")\n",
        "\n",
        "    # Compute total sample size\n",
        "    total_sample_size = len(data_df['Subject ID'].unique())\n",
        "\n",
        "    # Plot Accuracy by Block and Image Rating with overlaid participant averages\n",
        "    plt.figure(figsize=(16, 8))  # Increase the width of the plot\n",
        "    ax = sns.barplot(\n",
        "        data=data_df,\n",
        "        x='Block Type',\n",
        "        y='Correct (Binary)',\n",
        "        hue='Image Rating',\n",
        "        hue_order=rating_order,  # Specify the order of the hue categories\n",
        "        errwidth=0  # Remove error bars for clarity\n",
        "    )\n",
        "\n",
        "    # Apply custom colors to bars based on Block Type and Image Rating\n",
        "    for patch, combination in zip(ax.patches, [(bt, ir) for bt in block_order for ir in rating_order]):\n",
        "        patch.set_color(custom_palette[combination])\n",
        "\n",
        "    # Overlay individual average accuracy points with different color intensity for contrast\n",
        "    sns.stripplot(\n",
        "        data=participant_means,\n",
        "        x='Block Type',\n",
        "        y='Correct (Binary)',\n",
        "        hue='Image Rating',\n",
        "        hue_order=rating_order,\n",
        "        dodge=True,  # Separate the points by hue category\n",
        "        marker='o',  # Use circles for the points\n",
        "        palette=['k']*len(rating_order),  # Use consistent color for points\n",
        "        alpha=0.6,  # Set transparency of the points\n",
        "        ax=ax,\n",
        "        linewidth=1,  # Add a border around the points\n",
        "        edgecolor='gray'  # Set the border color\n",
        "    )\n",
        "\n",
        "    # Remove the overlapping legends for the stripplot\n",
        "    for patch in ax.artists:\n",
        "        patch.set_visible(False)\n",
        "\n",
        "    # Add p-values to the plot\n",
        "    y_offset = 0.8  # baseline for p values\n",
        "    indicator_offset = 0.05  # Increment added to y_offset for each new p-value\n",
        "\n",
        "    # Loop through comparisons and add to plot\n",
        "    for block, rating1, rating2, stat, p_value in comparisons:\n",
        "        block_index = block_order.index(block)\n",
        "        bar_l_pos = block_index - 0.1\n",
        "        bar_r_pos = block_index + 0.1\n",
        "        h = 0.02\n",
        "        p_value_text = \"p<.001\" if p_value < 0.001 else f\"p = {p_value:.3f}\"\n",
        "        plt.plot([bar_l_pos, bar_r_pos], [y_offset, y_offset], lw=0.5, c='k')  # Set the line width to 0.5\n",
        "        plt.text((bar_l_pos + bar_r_pos) * .5, y_offset + h, p_value_text, ha='center', va='bottom', color='k', fontsize=18)\n",
        "        y_offset += indicator_offset\n",
        "\n",
        "    plt.title(f'{title_suffix} Participants (n={total_sample_size})', fontsize=26, fontweight='bold')  # Bold title\n",
        "    plt.axhline(y=0.5, color='gray', linestyle='--', lw=1, label='Chance Level')  # Set the linewidth for the horizontal line\n",
        "    plt.ylim(0, 1.1)  # Set y-axis limits to 0-1.1\n",
        "    plt.xlabel('Block Type', fontsize=24, fontweight='bold')  # Bold xlabel\n",
        "    plt.ylabel('Average Accuracy', fontsize=24, fontweight='bold')  # Bold ylabel\n",
        "    plt.xticks(fontsize=20)  # Keep x-axis labels horizontal for better readability\n",
        "    plt.yticks(fontsize=18)\n",
        "\n",
        "    # Adjust the thickness of the plot outline (axes lines)\n",
        "    for spine in ax.spines.values():\n",
        "        spine.set_linewidth(1)  # Set the linewidth for the plot outline\n",
        "\n",
        "    # Manually create the legend\n",
        "    plus5_patch = mpatches.Patch(color=new_palette[0], label='+5 outcome')\n",
        "    minus5_patch = mpatches.Patch(color=new_palette[1], label='-5 outcome')\n",
        "    chance_level_line = Line2D([0], [0], color='gray', linestyle='--', label='Chance Level')\n",
        "\n",
        "    # Move the legend to the side of the plot\n",
        "    plt.legend(handles=[plus5_patch, minus5_patch, chance_level_line], title='Associated Outcome (on 90% of trials)',\n",
        "               bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20, title_fontsize=22)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.grid(False)\n",
        "\n",
        "    # Modify tick parameters to increase the length of tick marks\n",
        "    ax.tick_params(axis='both', which='both', length=10)  # Increase tick mark length\n",
        "    plt.show()\n",
        "\n",
        "# Assuming aligned_start_df and unaligned_start_df are already defined and loaded with the appropriate data\n",
        "\n",
        "# Plot for congruent-start participants\n",
        "plot_accuracy_by_block_image_rating(aligned_start_df, 'Congruent Start')\n",
        "\n",
        "# Plot for incongruent-start participants\n",
        "plot_accuracy_by_block_image_rating(unaligned_start_df, 'Incongruent Start')"
      ],
      "metadata": {
        "id": "QNQbLAoCYYmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average accuracy overall (collapsed across blocks) by trial type and by stimulus valence"
      ],
      "metadata": {
        "id": "XS_rn7rFYaVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_ind, chi2_contingency\n",
        "import numpy as np\n",
        "\n",
        "# Assuming all_participants_df is the DataFrame that contains the concatenated data for all participants\n",
        "# Replace the following line with the actual definition of all_participants_df\n",
        "# all_participants_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# Ensure all required columns exist\n",
        "required_columns = ['Subject ID', 'Trial type', 'Correct (Theoretical)', 'Image Rating']\n",
        "if not all(col in all_participants_df.columns for col in required_columns):\n",
        "    raise ValueError(\"Required columns are missing in the data.\")\n",
        "\n",
        "# Convert 'Correct (Theoretical)' to binary (1 for True, 0 for False)\n",
        "all_participants_df['Correct (Binary)'] = all_participants_df['Correct (Theoretical)'].astype(int)\n",
        "all_participants_df['Correct (Theoretical)'] = all_participants_df['Correct (Theoretical)'].astype(int)  # Convert Correct (Theoretical) to integer type\n",
        "\n",
        "# Accuracy per 'Trial type' (aligned and unaligned)\n",
        "trial_type_accuracy_all = all_participants_df.groupby('Trial type')['Correct (Theoretical)'].mean()\n",
        "ttest_p_value_tt_all = ttest_ind(\n",
        "    all_participants_df[all_participants_df['Trial type'] == 'aligned']['Correct (Theoretical)'],\n",
        "    all_participants_df[all_participants_df['Trial type'] == 'unaligned']['Correct (Theoretical)'],\n",
        "    nan_policy='omit'\n",
        ").pvalue\n",
        "\n",
        "# Calculate Cohen's d for aligned vs unaligned trial types\n",
        "aligned_mean = all_participants_df[all_participants_df['Trial type'] == 'aligned']['Correct (Theoretical)'].mean()\n",
        "unaligned_mean = all_participants_df[all_participants_df['Trial type'] == 'unaligned']['Correct (Theoretical)'].mean()\n",
        "aligned_std = all_participants_df[all_participants_df['Trial type'] == 'aligned']['Correct (Theoretical)'].std(ddof=1)\n",
        "unaligned_std = all_participants_df[all_participants_df['Trial type'] == 'unaligned']['Correct (Theoretical)'].std(ddof=1)\n",
        "aligned_n = all_participants_df[all_participants_df['Trial type'] == 'aligned'].shape[0]\n",
        "unaligned_n = all_participants_df[all_participants_df['Trial type'] == 'unaligned'].shape[0]\n",
        "\n",
        "pooled_std = np.sqrt(((aligned_n - 1) * aligned_std**2 + (unaligned_n - 1) * unaligned_std**2) / (aligned_n + unaligned_n - 2))\n",
        "cohens_d = (aligned_mean - unaligned_mean) / pooled_std\n",
        "\n",
        "# Accuracy as a function of 'Image Rating'\n",
        "# Create a contingency table\n",
        "contingency_table_all = pd.crosstab(all_participants_df['Image Rating'], all_participants_df['Correct (Binary)'])\n",
        "\n",
        "# Perform chi-squared test\n",
        "chi2_all, p_all, _, _ = chi2_contingency(contingency_table_all)\n",
        "\n",
        "# Output results\n",
        "print(\"\\nAccuracy per 'Trial type' (aligned and unaligned) (average across participants):\")\n",
        "print(trial_type_accuracy_all)\n",
        "print(f\"t-test p-value for 'Trial type' (average across participants): {ttest_p_value_tt_all}\")\n",
        "print(f\"Cohen's d for 'Trial type' (aligned vs. unaligned): {cohens_d:.3f}\")\n",
        "\n",
        "print(\"\\nAccuracy as a function of 'Image Rating' (average across participants):\")\n",
        "print(all_participants_df.groupby('Image Rating')['Correct (Binary)'].mean())\n",
        "print(f\"Chi-squared p-value for 'Image Rating' (average across participants): {p_all:.15f}\")\n",
        "print(\"Data for Chi-squared test (average across participants):\")\n",
        "print(contingency_table_all)\n",
        "\n",
        "# Visualization\n",
        "# First, calculate the average accuracy per participant for each Trial type and Image Rating\n",
        "avg_accuracy_by_trial_type = all_participants_df.groupby(['Subject ID', 'Trial type'])['Correct (Theoretical)'].mean().reset_index()\n",
        "avg_accuracy_by_image_rating = all_participants_df.groupby(['Subject ID', 'Image Rating'])['Correct (Theoretical)'].mean().reset_index()\n",
        "\n",
        "# Accuracy by Trial Type and Image Rating\n",
        "fig, axs = plt.subplots(1, 2, figsize=(20, 8), gridspec_kw={'wspace': 0.5})  # Increase wspace for more spacing\n",
        "\n",
        "# Define custom color palette\n",
        "paired_palette = sns.color_palette(\"Paired\")  # You can choose any palette\n",
        "# Assign specific colors from the Paired palette\n",
        "palette = {'aligned': paired_palette[0], 'unaligned': paired_palette[1],\n",
        "           'strongly_dislike': paired_palette[7], 'dislike': paired_palette[7],\n",
        "           'like': paired_palette[9], 'strongly_like': paired_palette[9]}\n",
        "\n",
        "# Accuracy by Trial Type (with individual subject data points)\n",
        "sns.barplot(x='Trial type', y='Correct (Theoretical)', data=all_participants_df,\n",
        "            ax=axs[0], palette=palette, ci=None, order=['aligned', 'unaligned'])\n",
        "sns.stripplot(x='Trial type', y='Correct (Theoretical)', data=avg_accuracy_by_trial_type,\n",
        "              ax=axs[0], jitter=True, color='black', size=4, alpha=0.7)\n",
        "axs[0].set_title('Average Accuracy by Trial Type Across All Participants', fontsize=18, fontweight='bold')\n",
        "axs[0].set_xlabel('Trial type', fontsize=16, fontweight='bold')\n",
        "axs[0].set_ylabel('Average Accuracy', fontsize=16, fontweight='bold')\n",
        "axs[0].tick_params(axis='both', which='major', labelsize=14)  # Increase tick mark labels size\n",
        "if ttest_p_value_tt_all < 0.05:\n",
        "    height = max(all_participants_df.groupby('Trial type')['Correct (Theoretical)'].max()) + 0.05\n",
        "    axs[0].plot([0, 1], [height, height], linewidth=1, color='k')\n",
        "    axs[0].text(0.5, height + 0.01, f'p={ttest_p_value_tt_all:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Accuracy by Image Rating (with individual subject data points)\n",
        "sns.barplot(x='Image Rating', y='Correct (Theoretical)', data=all_participants_df,\n",
        "            ax=axs[1], palette=palette, ci=None, order=['strongly_dislike', 'dislike', 'like', 'strongly_like'])\n",
        "sns.stripplot(x='Image Rating', y='Correct (Theoretical)', data=avg_accuracy_by_image_rating,\n",
        "              ax=axs[1], jitter=True, color='black', size=4, alpha=0.7)\n",
        "axs[1].set_title('Average Accuracy by Image Rating Across All Participants', fontsize=18, fontweight='bold')\n",
        "axs[1].set_xlabel('Image Rating', fontsize=16, fontweight='bold')\n",
        "axs[1].set_ylabel('Average Accuracy', fontsize=16, fontweight='bold')\n",
        "axs[1].set_xticklabels(['strongly dislike', 'dislike', 'like', 'strongly like'])\n",
        "axs[1].tick_params(axis='both', which='major', labelsize=14)  # Increase tick mark labels size\n",
        "if p_all < 0.05:\n",
        "    height = max(all_participants_df.groupby('Image Rating')['Correct (Theoretical)'].max()) + 0.05\n",
        "    axs[1].plot([0, 1, 2, 3], [height, height, height, height], linewidth=1, color='k')\n",
        "    axs[1].text(1.5, height + 0.01, f'p={p_all:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eMsW_CyEYb-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Average accuracy per block as a function of image rating and trial type (separated by start group)"
      ],
      "metadata": {
        "id": "pfuNozZiYdvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "def analyze_and_plot_violin_anova(all_participants_df, rating_filter):\n",
        "    if all_participants_df.empty:\n",
        "        print(\"No data available for analysis.\")\n",
        "        return\n",
        "\n",
        "    # Filter for food items based on 'Image Rating' column\n",
        "    filtered_df = all_participants_df[all_participants_df['Image Rating'].isin(rating_filter)]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        print(\"No data available after filtering for specified food items.\")\n",
        "        return\n",
        "\n",
        "    # Replicate the starting group split logic from Script 2\n",
        "    congruent_data = []\n",
        "    incongruent_data = []\n",
        "    for subject_id, df in filtered_df.groupby('Subject ID'):\n",
        "        first_trial_type = df['Trial type'].iloc[0]\n",
        "        if first_trial_type == 'aligned':\n",
        "            congruent_data.append(df)\n",
        "        else:\n",
        "            incongruent_data.append(df)\n",
        "\n",
        "    if len(congruent_data) == 0 or len(incongruent_data) == 0:\n",
        "        print(\"No data available after splitting by starting trial type.\")\n",
        "        return\n",
        "\n",
        "    congruent_start_df = pd.concat(congruent_data)\n",
        "    incongruent_start_df = pd.concat(incongruent_data)\n",
        "\n",
        "    # Combine data for aligned and unaligned participants\n",
        "    congruent_start_df['Group'] = 'C-start'\n",
        "    incongruent_start_df['Group'] = 'I-start'\n",
        "    combined_data_df = pd.concat([congruent_start_df, incongruent_start_df])\n",
        "\n",
        "    # Calculate mean accuracy per participant for 'Trial type' and 'Group'\n",
        "    mean_combinations = combined_data_df.groupby(['Subject ID', 'Trial type', 'Group'])['Correct (Theoretical)'].mean().reset_index()\n",
        "    mean_combinations['Trial type'] = mean_combinations['Trial type'].replace({'aligned': 'Congruent', 'unaligned': 'Incongruent'})\n",
        "\n",
        "    # Define the custom labels for plotting\n",
        "    mean_combinations['Combined_label'] = mean_combinations.apply(lambda x: f\"{x['Group']} {x['Trial type']} Trials\", axis=1)\n",
        "\n",
        "    # Conduct ANOVA\n",
        "    formula = 'Q(\"Correct (Theoretical)\") ~ Q(\"Trial type\") * Group'\n",
        "    model = ols(formula, data=mean_combinations).fit()\n",
        "    anova_results = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "    # Output ANOVA results\n",
        "    print(\"\\nANOVA results:\")\n",
        "    print(anova_results)\n",
        "\n",
        "    # Conduct Tukey's HSD post hoc test\n",
        "    mean_combinations['Group_Trial'] = mean_combinations['Group'] + \"_\" + mean_combinations['Trial type']\n",
        "    tukey_results = pairwise_tukeyhsd(endog=mean_combinations['Correct (Theoretical)'],\n",
        "                                      groups=mean_combinations['Group_Trial'],\n",
        "                                      alpha=0.05)\n",
        "\n",
        "    # Output post hoc results\n",
        "    print(\"\\nPost hoc test results (Tukey's HSD):\")\n",
        "    print(tukey_results)\n",
        "\n",
        "    # Define the custom color palette with specific colors from the 'Paired' palette\n",
        "    paired_palette = sns.color_palette(\"Paired\")\n",
        "    if 'like' in rating_filter:\n",
        "        trial_palette = {\n",
        "            'Congruent': paired_palette[9],   # Dark purple\n",
        "            'Incongruent': paired_palette[8]  # Light purple\n",
        "        }\n",
        "        title = 'Liked Items'\n",
        "    else:\n",
        "        trial_palette = {\n",
        "            'Congruent': paired_palette[7],   # Dark orange\n",
        "            'Incongruent': paired_palette[6]  # Light orange\n",
        "        }\n",
        "        title = 'Disliked Items'\n",
        "\n",
        "    # Adjust labels for grouping by 'Starting block'\n",
        "    mean_combinations['Starting_block'] = mean_combinations['Group']\n",
        "\n",
        "    # Update tick label names\n",
        "    tick_names = {\n",
        "        'C-start': 'Congruent-start',\n",
        "        'I-start': 'Incongruent-start'\n",
        "    }\n",
        "    mean_combinations['Starting_block'] = mean_combinations['Starting_block'].map(tick_names)\n",
        "\n",
        "    # Sort data to ensure 'Congruent-start' is plotted first\n",
        "    mean_combinations['Starting_block'] = pd.Categorical(mean_combinations['Starting_block'], categories=['Congruent-start', 'Incongruent-start'], ordered=True)\n",
        "\n",
        "    # Calculate and print out mean accuracy for each group\n",
        "    group_means = mean_combinations.groupby(['Starting_block', 'Trial type'])['Correct (Theoretical)'].mean()\n",
        "    group_stds = mean_combinations.groupby(['Starting_block', 'Trial type'])['Correct (Theoretical)'].std()\n",
        "    print(\"\\nMean accuracy for each group:\")\n",
        "    for (starting_block, trial_type), mean_accuracy in group_means.items():\n",
        "        std_dev = group_stds.loc[starting_block, trial_type]\n",
        "        print(f\"{starting_block}, {trial_type}: Mean Accuracy = {mean_accuracy:.4f} ± {std_dev:.4f}\")\n",
        "\n",
        "    # Create figure and plot violin plot\n",
        "    plt.figure(figsize=(18, 8))\n",
        "    base_positions = {'Congruent-start': 0, 'Incongruent-start': 1}\n",
        "    sns.violinplot(x='Starting_block', y='Correct (Theoretical)', hue='Trial type', data=mean_combinations,\n",
        "                   palette=trial_palette, split=False, inner=None, dodge=True)\n",
        "    sns.stripplot(x='Starting_block', y='Correct (Theoretical)', hue='Trial type', data=mean_combinations,\n",
        "                  jitter=True, color='black', alpha=0.6, dodge=True)\n",
        "\n",
        "    # Overlay means and IQRs\n",
        "    offsets = {'Congruent': -0.2, 'Incongruent': 0.2}  # Adjusting offsets for better alignment\n",
        "    for starting_block in mean_combinations['Starting_block'].unique():\n",
        "        for trial_type in mean_combinations['Trial type'].unique():\n",
        "            subset = mean_combinations[(mean_combinations['Starting_block'] == starting_block) &\n",
        "                                       (mean_combinations['Trial type'] == trial_type)]\n",
        "            base_position = base_positions[starting_block]\n",
        "            xpos = base_position + offsets[trial_type]\n",
        "\n",
        "            mean_val = subset['Correct (Theoretical)'].mean()\n",
        "            q25, q75 = subset['Correct (Theoretical)'].quantile([0.25, 0.75])\n",
        "\n",
        "            # Plotting mean and IQR\n",
        "            plt.scatter(x=[xpos], y=[mean_val], color='lightgray', s=20, zorder=3)\n",
        "            plt.plot([xpos, xpos], [q25, q75], color='gray', lw=3, solid_capstyle='butt', zorder=2)\n",
        "\n",
        "    plt.xlabel('Starting block', fontsize=24, fontweight='bold')\n",
        "    plt.ylabel('Average Accuracy', fontsize=24, fontweight='bold')\n",
        "    plt.title(title, fontsize=26, fontweight='bold')\n",
        "    plt.xticks([0, 1], ['Congruent-start', 'Incongruent-start'], fontsize=20)\n",
        "    plt.yticks(fontsize=18)\n",
        "\n",
        "    # Handle legend properly\n",
        "    handles, labels = plt.gca().get_legend_handles_labels()\n",
        "    unique_labels = dict(zip(labels, handles))\n",
        "\n",
        "    # Update the legend to have the desired labels\n",
        "    if 'like' in rating_filter:\n",
        "        correct_labels = ['Congruent (Gains)', 'Incongruent (Losses)']\n",
        "    else:\n",
        "        correct_labels = ['Congruent (Losses)', 'Incongruent (Gains)']\n",
        "    plt.legend(handles[:2], correct_labels, title='Trial type', fontsize=20, title_fontsize='19')\n",
        "\n",
        "    sns.despine()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with dataframes\n",
        "analyze_and_plot_violin_anova(all_participants_df, ['like', 'strongly_like'])\n",
        "analyze_and_plot_violin_anova(all_participants_df, ['dislike', 'strongly_dislike'])"
      ],
      "metadata": {
        "id": "s1psS006YfXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy time course as a function of image rating (separated by start group)\n"
      ],
      "metadata": {
        "id": "3fk-qC72YhQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import wilcoxon\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Define the color palette from the 'Paired' color palette\n",
        "paired_palette = sns.color_palette(\"Paired\")\n",
        "purple_palette = [paired_palette[8], paired_palette[9]]  # lighter and darker purple colors respectively\n",
        "orange_palette = [paired_palette[6], paired_palette[7]]  # lighter and darker orange colors respectively\n",
        "\n",
        "# Mapping colors to ratings\n",
        "rating_to_colors = {\n",
        "    'strongly_like': {'congruent': purple_palette[1], 'incongruent': purple_palette[0]},\n",
        "    'like': {'congruent': purple_palette[1], 'incongruent': purple_palette[0]},\n",
        "    'dislike': {'congruent': orange_palette[1], 'incongruent': orange_palette[0]},\n",
        "    'strongly_dislike': {'congruent': orange_palette[1], 'incongruent': orange_palette[0]}\n",
        "}\n",
        "\n",
        "def plot_accuracy_by_block(df, rating):\n",
        "    # Initialize empty lists to store aggregated data\n",
        "    all_block_counts = []\n",
        "    all_block_accuracy = []\n",
        "    congruent_start_count = 0\n",
        "    incongruent_start_count = 0\n",
        "\n",
        "    # Filter dataframe by the specific image rating\n",
        "    filtered_df = df[df['Image Rating'] == rating]\n",
        "\n",
        "    # Iterate over each participant's data in the combined DataFrame\n",
        "    for subject_id, df_part in filtered_df.groupby('Subject ID'):\n",
        "        # Define blocks based on switches in 'Trial type'\n",
        "        df_part['Block Number'] = (df_part['Trial type'] != df_part['Trial type'].shift(1)).cumsum()\n",
        "        df_part['Block'] = df_part['Block Number'].astype(str) + df_part['Trial type'].apply(lambda x: 'C' if x == 'aligned' else 'I')\n",
        "\n",
        "        # Count how many participants started with congruent vs incongruent\n",
        "        first_trial_type = df_part['Trial type'].iloc[0]\n",
        "        if first_trial_type == 'aligned':\n",
        "            congruent_start_count += 1\n",
        "        else:\n",
        "            incongruent_start_count += 1\n",
        "\n",
        "        # Accuracy in each 'Block'\n",
        "        block_accuracy = df_part.groupby('Block')['Correct (Theoretical)'].mean()\n",
        "\n",
        "        # Append data to lists\n",
        "        all_block_accuracy.append(block_accuracy)\n",
        "\n",
        "    # Plotting across participants\n",
        "\n",
        "    # Separate data for 'Congruent' and 'Incongruent' starts\n",
        "    congruent_data = [block_accuracy for block_accuracy in all_block_accuracy if 'C' in block_accuracy.index[0]]\n",
        "    incongruent_data = [block_accuracy for block_accuracy in all_block_accuracy if 'I' in block_accuracy.index[0]]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Determine colors based on rating\n",
        "    congruent_color = rating_to_colors[rating]['congruent']\n",
        "    incongruent_color = rating_to_colors[rating]['incongruent']\n",
        "\n",
        "    # Plot for Congruent starts if there is any data\n",
        "    if congruent_data:\n",
        "        for block_accuracy in congruent_data:\n",
        "            plt.plot(block_accuracy.index, block_accuracy, color='LightGrey', alpha=0.3)  # Faint grey lines for individual accuracies\n",
        "\n",
        "        congruent_data_df = pd.concat(congruent_data, axis=1)\n",
        "        avg_congruent_accuracy = congruent_data_df.mean(axis=1)\n",
        "        sem_congruent_accuracy = congruent_data_df.sem(axis=1)  # Standard Error of the Mean (SEM)\n",
        "\n",
        "        plt.errorbar(avg_congruent_accuracy.index, avg_congruent_accuracy, yerr=sem_congruent_accuracy, fmt='o-', color=congruent_color, label='Average Congruent-Start Accuracy')\n",
        "\n",
        "    # Plot for Incongruent starts if there is any data\n",
        "    if incongruent_data:\n",
        "        for block_accuracy in incongruent_data:\n",
        "            plt.plot(block_accuracy.index, block_accuracy, color='LightGrey', alpha=0.3)  # Faint grey lines for individual accuracies\n",
        "\n",
        "        incongruent_data_df = pd.concat(incongruent_data, axis=1)\n",
        "        avg_incongruent_accuracy = incongruent_data_df.mean(axis=1)\n",
        "        sem_incongruent_accuracy = incongruent_data_df.sem(axis=1)  # Standard Error of the Mean (SEM)\n",
        "\n",
        "        plt.errorbar(avg_incongruent_accuracy.index, avg_incongruent_accuracy, yerr=sem_incongruent_accuracy, fmt='o-', color=incongruent_color, label='Average Incongruent-Start Accuracy')\n",
        "\n",
        "    # Adding the dotted dark grey line at 0.5 for chance level\n",
        "    plt.axhline(y=0.5, color='darkgrey', linestyle='--', linewidth=1, label='Chance Level')\n",
        "\n",
        "    # Only show plot if there is data\n",
        "    if congruent_data or incongruent_data:\n",
        "        plt.xlabel('Block', fontsize=16, fontweight='bold')\n",
        "        plt.ylabel('Average Accuracy', fontsize=16, fontweight='bold')\n",
        "        plt.xticks(fontsize=14)  # Increase the font size of x-axis tick marks\n",
        "        plt.yticks(fontsize=14)  # Increase the font size of y-axis tick marks\n",
        "        plt.title(f'{rating.replace(\"_\", \" \").title()} \\nCongruent Start Participants (n={congruent_start_count}) \\nIncongruent Start Participants (n={incongruent_start_count})', fontsize=18, fontweight='bold')\n",
        "        plt.legend()\n",
        "        plt.grid(False)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No data available for congruent or incongruent starts for {rating}.\")\n",
        "\n",
        "    # Initialize lists to store results\n",
        "    significant_blocks_congruent = []\n",
        "    significant_blocks_incongruent = []\n",
        "\n",
        "    # Wilcoxon signed-rank test for congruent data\n",
        "    if congruent_data:\n",
        "        for block in avg_congruent_accuracy.index:\n",
        "            block_values = [block_acc.loc[block] for block_acc in congruent_data if block in block_acc.index]\n",
        "            if len(block_values) > 0:\n",
        "                w_stat, p_value = wilcoxon(np.array(block_values) - 0.5, alternative='greater')\n",
        "                if p_value < 0.05:\n",
        "                    significant_blocks_congruent.append((block, w_stat, p_value))\n",
        "\n",
        "    # Wilcoxon signed-rank test for incongruent data\n",
        "    if incongruent_data:\n",
        "        for block in avg_incongruent_accuracy.index:\n",
        "            block_values = [block_acc.loc[block] for block_acc in incongruent_data if block in block_acc.index]\n",
        "            if len(block_values) > 0:\n",
        "                w_stat, p_value = wilcoxon(np.array(block_values) - 0.5, alternative='greater')\n",
        "                if p_value < 0.05:\n",
        "                    significant_blocks_incongruent.append((block, w_stat, p_value))\n",
        "\n",
        "    # Print out the results\n",
        "    print(f\"\\nSignificant blocks for congruent start participants (accuracy significantly above 0.5) for {rating}:\")\n",
        "    for block, w_stat, p_value in significant_blocks_congruent:\n",
        "        print(f\"Block {block}: Wilcoxon statistic = {w_stat:.3f}, p-value = {p_value:.6f}\")\n",
        "\n",
        "    print(f\"\\nSignificant blocks for incongruent start participants (accuracy significantly above 0.5) for {rating}:\")\n",
        "    for block, w_stat, p_value in significant_blocks_incongruent:\n",
        "        print(f\"Block {block}: Wilcoxon statistic = {w_stat:.3f}, p-value = {p_value:.6f}\")\n",
        "\n",
        "    # Preparing data for 2x2 ANOVA\n",
        "    anova_data = {\n",
        "        'Start_Type': [],\n",
        "        'Trial_Type': [],\n",
        "        'Accuracy': []\n",
        "    }\n",
        "\n",
        "    for subject_id, df_part in filtered_df.groupby('Subject ID'):\n",
        "        first_trial_type = df_part['Trial type'].iloc[0]\n",
        "        start_type = 'Congruent' if first_trial_type == 'aligned' else 'Incongruent'\n",
        "        for trial_type, sub_df in df_part.groupby('Trial type'):\n",
        "            average_accuracy = sub_df['Correct (Theoretical)'].mean()\n",
        "            trial_label = 'Congruent_Trial_Type' if trial_type == 'aligned' else 'Incongruent_Trial_Type'\n",
        "            anova_data['Start_Type'].append(start_type)\n",
        "            anova_data['Trial_Type'].append(trial_label)\n",
        "            anova_data['Accuracy'].append(average_accuracy)\n",
        "\n",
        "    anova_df = pd.DataFrame(anova_data)\n",
        "\n",
        "    # 2x2 ANOVA for each rating\n",
        "    model = ols('Accuracy ~ C(Start_Type) * C(Trial_Type)', data=anova_df).fit()\n",
        "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "    print(f\"\\nANOVA table for rating {rating}:\\n\")\n",
        "    print(anova_table)\n",
        "\n",
        "# Define the image ratings\n",
        "image_ratings = ['strongly_like', 'like', 'dislike', 'strongly_dislike']\n",
        "\n",
        "# Iterate over each rating and generate the plots and ANOVAs\n",
        "for rating in image_ratings:\n",
        "    plot_accuracy_by_block(all_participants_df, rating)"
      ],
      "metadata": {
        "id": "61ZCJYa9YirI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 3 way ANOVA with 4 image rating categories\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# Assuming all_participants_df is defined and contains the data.\n",
        "\n",
        "# Add a column representing the starting trial type\n",
        "def add_starting_trial_type(df):\n",
        "    df['Starting_Trial'] = df.groupby('Subject ID')['Trial type'].transform(lambda x: 'Aligned' if x.iloc[0] == 'aligned' else 'Unaligned')\n",
        "    return df\n",
        "\n",
        "# Apply the function to add the starting trial type\n",
        "all_participants_df = add_starting_trial_type(all_participants_df)\n",
        "\n",
        "# Rename columns for clarity and ease of use in ANOVA\n",
        "anova_data = all_participants_df.copy()\n",
        "anova_data.rename(columns={\n",
        "    'Image Rating': 'Image_Rating',\n",
        "    'Trial type': 'Trial_Type',\n",
        "    'Correct (Theoretical)': 'Correct_Theoretical'\n",
        "}, inplace=True)\n",
        "\n",
        "# Convert Correct_Theoretical to numeric (1 for True, 0 for False)\n",
        "anova_data['Correct_Theoretical'] = anova_data['Correct_Theoretical'].astype(int)\n",
        "\n",
        "# Print the number of participants for verification\n",
        "num_participants = anova_data['Subject ID'].nunique()\n",
        "print(f\"Number of participants: {num_participants}\")\n",
        "\n",
        "# Print total number of trials for verification\n",
        "total_trials = len(anova_data)\n",
        "print(f\"Total number of trials: {total_trials}\")\n",
        "\n",
        "# Prepare data for ANOVA\n",
        "anova_data_dict = {\n",
        "    'Start_Type': [],\n",
        "    'Trial_Type': [],\n",
        "    'Image_Rating': [],\n",
        "    'Accuracy': [],\n",
        "    'Subject_ID': []  # Keep track of subject ID for better understanding of the data\n",
        "}\n",
        "\n",
        "for subject_id, df in all_participants_df.groupby('Subject ID'):\n",
        "    first_trial_type = df['Trial type'].iloc[0]\n",
        "    start_type = 'Aligned' if first_trial_type == 'aligned' else 'Unaligned'\n",
        "    for (trial_type, image_rating), sub_df in df.groupby(['Trial type', 'Image Rating']):\n",
        "        average_accuracy = sub_df['Correct (Theoretical)'].mean()\n",
        "        trial_label = 'Aligned_Trial_Type' if trial_type == 'aligned' else 'Unaligned_Trial_Type'\n",
        "        anova_data_dict['Start_Type'].append(start_type)\n",
        "        anova_data_dict['Trial_Type'].append(trial_label)\n",
        "        anova_data_dict['Image_Rating'].append(image_rating)\n",
        "        anova_data_dict['Accuracy'].append(average_accuracy)\n",
        "        anova_data_dict['Subject_ID'].append(subject_id)\n",
        "\n",
        "anova_df = pd.DataFrame(anova_data_dict)\n",
        "\n",
        "# Print aggregated data count for verification\n",
        "print(f\"Number of rows in aggregated data: {len(anova_df)}\")\n",
        "\n",
        "# 3-way ANOVA\n",
        "model = ols('Accuracy ~ C(Start_Type) * C(Trial_Type) * C(Image_Rating)', data=anova_df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(\"3-Way ANOVA Table:\")\n",
        "print(anova_table)\n",
        "\n",
        "# Extract degrees of freedom, F-statistic, and p-value for each term\n",
        "for term, row in anova_table.iterrows():\n",
        "    df1 = int(row['df'])\n",
        "    df2 = int(anova_table['df'][term] + anova_table['df']['Residual'])\n",
        "    F = row['F']\n",
        "    p = row['PR(>F)']\n",
        "    print(f\"Term: {term}, F({df1}, {df2}) = {F:.2f}, p = {'< .001' if p < .001 else f'{p:.3f}'}\")\n",
        "\n",
        "# Tukey's HSD post hoc analysis for significant main effects and interactions\n",
        "mc = pairwise_tukeyhsd(anova_df['Accuracy'],\n",
        "                       anova_df['Start_Type'] + \"_\" + anova_df['Trial_Type'] + \"_\" + anova_df['Image_Rating'],\n",
        "                       alpha=0.05)\n",
        "\n",
        "print(\"\\nTukey's HSD post hoc test results:\")\n",
        "print(mc)"
      ],
      "metadata": {
        "id": "xLxrjrf1YlsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import wilcoxon\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Assuming all_participants_df is already created with the combined data\n",
        "\n",
        "# Define the custom color palette with specific purple colors from the 'Paired' palette\n",
        "paired_palette = sns.color_palette(\"Paired\")\n",
        "purple_palette = [paired_palette[8], paired_palette[9]]  # lighter and darker purple colors respectively\n",
        "palette = {\n",
        "    'C-start': purple_palette[1],\n",
        "    'I-start': purple_palette[0]\n",
        "}\n",
        "\n",
        "# Define the custom color palette with specific orange colors from the 'Paired' palette\n",
        "trial_palette = {\n",
        "    'Congruent start': paired_palette[7],  # Dark orange\n",
        "    'Incongruent start': paired_palette[6]  # Light orange\n",
        "}\n",
        "\n",
        "def plot_accuracy_by_block(df, rating_group, group_label):\n",
        "    # Initialize empty lists to store aggregated data\n",
        "    all_block_counts = []\n",
        "    all_block_accuracy = []\n",
        "    congruent_start_count = 0\n",
        "    incongruent_start_count = 0\n",
        "\n",
        "    # Filter dataframe by the specific image rating group\n",
        "    df = df[df['Image Rating'].isin(rating_group)]\n",
        "\n",
        "    # Iterate over each participant's data in the combined DataFrame\n",
        "    for subject_id, df_part in df.groupby('Subject ID'):\n",
        "        # Define blocks based on switches in 'Trial type'\n",
        "        df_part['Block Number'] = (df_part['Trial type'] != df_part['Trial type'].shift(1)).cumsum()\n",
        "        df_part['Block'] = df_part['Block Number'].astype(str) + df_part['Trial type'].apply(lambda x: 'C' if x == 'aligned' else 'I')\n",
        "\n",
        "        # Count how many participants started with congruent vs incongruent\n",
        "        first_trial_type = df_part['Trial type'].iloc[0]\n",
        "        if first_trial_type == 'aligned':\n",
        "            congruent_start_count += 1\n",
        "        else:\n",
        "            incongruent_start_count += 1\n",
        "\n",
        "        # Accuracy in each 'Block'\n",
        "        block_accuracy = df_part.groupby('Block')['Correct (Theoretical)'].mean()\n",
        "\n",
        "        # Append data to lists\n",
        "        all_block_accuracy.append(block_accuracy)\n",
        "\n",
        "    # Plotting across participants\n",
        "\n",
        "    # Separate data for 'Congruent' and 'Incongruent' starts\n",
        "    congruent_data = [block_accuracy for block_accuracy in all_block_accuracy if 'C' in block_accuracy.index[0]]\n",
        "    incongruent_data = [block_accuracy for block_accuracy in all_block_accuracy if 'I' in block_accuracy.index[0]]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Determine colors based on rating group\n",
        "    if group_label == 'Like':\n",
        "        congruent_color = palette['C-start']\n",
        "        incongruent_color = palette['I-start']\n",
        "    else:\n",
        "        congruent_color = trial_palette['Congruent start']\n",
        "        incongruent_color = trial_palette['Incongruent start']\n",
        "\n",
        "    # Plot for Congruent starts if there is any data\n",
        "    if congruent_data:\n",
        "        for block_accuracy in congruent_data:\n",
        "            plt.plot(block_accuracy.index, block_accuracy, color='LightGrey', alpha=0.3)  # Faint grey lines for individual accuracies\n",
        "\n",
        "        congruent_data_df = pd.concat(congruent_data, axis=1)\n",
        "        avg_congruent_accuracy = congruent_data_df.mean(axis=1)\n",
        "        sem_congruent_accuracy = congruent_data_df.sem(axis=1)  # Standard Error of the Mean (SEM)\n",
        "\n",
        "        plt.errorbar(avg_congruent_accuracy.index, avg_congruent_accuracy, yerr=sem_congruent_accuracy, fmt='o-', color=congruent_color, label='Average Congruent-Start Accuracy')\n",
        "\n",
        "    # Plot for Incongruent starts if there is any data\n",
        "    if incongruent_data:\n",
        "        for block_accuracy in incongruent_data:\n",
        "            plt.plot(block_accuracy.index, block_accuracy, color='LightGrey', alpha=0.3)  # Faint grey lines for individual accuracies\n",
        "\n",
        "        incongruent_data_df = pd.concat(incongruent_data, axis=1)\n",
        "        avg_incongruent_accuracy = incongruent_data_df.mean(axis=1)\n",
        "        sem_incongruent_accuracy = incongruent_data_df.sem(axis=1)  # Standard Error of the Mean (SEM)\n",
        "\n",
        "        plt.errorbar(avg_incongruent_accuracy.index, avg_incongruent_accuracy, yerr=sem_incongruent_accuracy, fmt='o-', color=incongruent_color, label='Average Incongruent-Start Accuracy')\n",
        "\n",
        "    # Adding the dotted dark grey line at 0.5 for chance level\n",
        "    plt.axhline(y=0.5, color='darkgrey', linestyle='--', linewidth=1, label='Chance Level')\n",
        "\n",
        "    # Only show plot if there is data\n",
        "    if congruent_data or incongruent_data:\n",
        "        plt.xlabel('Block')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Accuracy by Block for {group_label} (Congruent starts: {congruent_start_count}, Incongruent starts: {incongruent_start_count})')\n",
        "        plt.legend()\n",
        "        plt.grid(False)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No data available for congruent or incongruent starts for {group_label}.\")\n",
        "\n",
        "    # Initialize lists to store results\n",
        "    significant_blocks_congruent = []\n",
        "    significant_blocks_incongruent = []\n",
        "\n",
        "    # Non-parametric test (Wilcoxon signed-rank test) for congruent data\n",
        "    if congruent_data:\n",
        "        for block in avg_congruent_accuracy.index:\n",
        "            block_values = [block_acc.loc[block] for block_acc in congruent_data if block in block_acc.index]\n",
        "            if len(block_values) > 0:  # Wilcoxon signed-rank requires at least one data point\n",
        "                w_stat, p_value = wilcoxon(np.array(block_values) - 0.5, alternative='greater')\n",
        "                if p_value < 0.05:\n",
        "                    significant_blocks_congruent.append((block, w_stat, p_value))\n",
        "\n",
        "    # Non-parametric test (Wilcoxon signed-rank test) for incongruent data\n",
        "    if incongruent_data:\n",
        "        for block in avg_incongruent_accuracy.index:\n",
        "            block_values = [block_acc.loc[block] for block_acc in incongruent_data if block in block_acc.index]\n",
        "            if len(block_values) > 0:  # Wilcoxon signed-rank requires at least one data point\n",
        "                w_stat, p_value = wilcoxon(np.array(block_values) - 0.5, alternative='greater')\n",
        "                if p_value < 0.05:\n",
        "                    significant_blocks_incongruent.append((block, w_stat, p_value))\n",
        "\n",
        "    # Print out the results\n",
        "    print(f\"\\nSignificant blocks for congruent start participants (accuracy significantly above 0.5) for {group_label}:\")\n",
        "    for block, w_stat, p_value in significant_blocks_congruent:\n",
        "        print(f\"Block {block}: Wilcoxon statistic = {w_stat:.3f}, p-value = {p_value:.6f}\")\n",
        "\n",
        "    print(f\"\\nSignificant blocks for incongruent start participants (accuracy significantly above 0.5) for {group_label}:\")\n",
        "    for block, w_stat, p_value in significant_blocks_incongruent:\n",
        "        print(f\"Block {block}: Wilcoxon statistic = {w_stat:.3f}, p-value = {p_value:.6f}\")\n",
        "\n",
        "    # Preparing data for 2x2 ANOVA\n",
        "    anova_data = {\n",
        "        'Start_Type': [],\n",
        "        'Trial_Type': [],\n",
        "        'Accuracy': []\n",
        "    }\n",
        "\n",
        "    for subject_id, df_part in df.groupby('Subject ID'):\n",
        "        first_trial_type = df_part['Trial type'].iloc[0]\n",
        "        start_type = 'Congruent' if first_trial_type == 'aligned' else 'Incongruent'\n",
        "        for trial_type, sub_df in df_part.groupby('Trial type'):\n",
        "            average_accuracy = sub_df['Correct (Theoretical)'].mean()\n",
        "            trial_label = 'Congruent_Trial_Type' if trial_type == 'aligned' else 'Incongruent_Trial_Type'\n",
        "            anova_data['Start_Type'].append(start_type)\n",
        "            anova_data['Trial_Type'].append(trial_label)\n",
        "            anova_data['Accuracy'].append(average_accuracy)\n",
        "\n",
        "    anova_df = pd.DataFrame(anova_data)\n",
        "\n",
        "    # 2x2 ANOVA for each rating group\n",
        "    model = ols('Accuracy ~ C(Start_Type) * C(Trial_Type)', data=anova_df).fit()\n",
        "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "    print(f\"\\nANOVA table for rating group {group_label}:\\n\")\n",
        "    print(anova_table)\n",
        "\n",
        "# Define the image rating groups\n",
        "liked_items = ['strongly_like', 'like']\n",
        "disliked_items = ['dislike', 'strongly_dislike']\n",
        "\n",
        "# Plot and analyze for each group\n",
        "plot_accuracy_by_block(all_participants_df, liked_items, 'Like')\n",
        "plot_accuracy_by_block(all_participants_df, disliked_items, 'Dislike')"
      ],
      "metadata": {
        "id": "LhBcSVm6YnN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# Assuming all_participants_df is defined and contains the data.\n",
        "print(f\"Raw Data Shape: {all_participants_df.shape}\")\n",
        "\n",
        "# Add a column representing the starting trial type\n",
        "def add_starting_trial_type(df):\n",
        "    df['Starting_Trial'] = df.groupby('Subject ID')['Trial type'].transform(lambda x: 'Aligned' if x.iloc[0] == 'aligned' else 'Unaligned')\n",
        "    return df\n",
        "\n",
        "# Apply the function to add the starting trial type\n",
        "all_participants_df = add_starting_trial_type(all_participants_df)\n",
        "\n",
        "# Rename columns for clarity and ease of use in ANOVA\n",
        "anova_data = all_participants_df.copy()\n",
        "anova_data.rename(columns={\n",
        "    'Image Rating': 'Image_Rating',\n",
        "    'Trial type': 'Trial_Type',\n",
        "    'Correct (Theoretical)': 'Correct_Theoretical'\n",
        "}, inplace=True)\n",
        "\n",
        "# Collapse image ratings into two categories: 'Liked' and 'Disliked'\n",
        "def collapse_ratings(rating):\n",
        "    if rating in ['strongly like', 'like']:\n",
        "        return 'Liked'\n",
        "    else:\n",
        "        return 'Disliked'\n",
        "\n",
        "anova_data['Image_Rating'] = anova_data['Image_Rating'].apply(collapse_ratings)\n",
        "\n",
        "# Convert Correct_Theoretical to numeric\n",
        "anova_data['Correct_Theoretical'] = anova_data['Correct_Theoretical'].astype(int)\n",
        "\n",
        "# Print number of participants and total trials\n",
        "num_participants = anova_data['Subject ID'].nunique()\n",
        "print(f\"Number of participants: {num_participants}\")\n",
        "total_trials = len(anova_data)\n",
        "print(f\"Total number of trials: {total_trials}\")\n",
        "\n",
        "# Prepare data for ANOVA\n",
        "anova_data_dict = {\n",
        "    'Start_Type': [],\n",
        "    'Trial_Type': [],\n",
        "    'Image_Rating': [],\n",
        "    'Accuracy': [],\n",
        "    'Subject_ID': []\n",
        "}\n",
        "\n",
        "for subject_id, df in anova_data.groupby('Subject ID'):\n",
        "    first_trial_type = df['Trial_Type'].iloc[0]\n",
        "    start_type = 'Aligned' if first_trial_type == 'aligned' else 'Unaligned'\n",
        "    for (trial_type, image_rating), sub_df in df.groupby(['Trial_Type', 'Image_Rating']):\n",
        "        average_accuracy = sub_df['Correct_Theoretical'].mean()\n",
        "        trial_label = 'Aligned_Trial_Type' if trial_type == 'aligned' else 'Unaligned_Trial_Type'\n",
        "        anova_data_dict['Start_Type'].append(start_type)\n",
        "        anova_data_dict['Trial_Type'].append(trial_label)\n",
        "        anova_data_dict['Image_Rating'].append(image_rating)\n",
        "        anova_data_dict['Accuracy'].append(average_accuracy)\n",
        "        anova_data_dict['Subject_ID'].append(subject_id)\n",
        "\n",
        "anova_df = pd.DataFrame(anova_data_dict)\n",
        "\n",
        "# Print aggregated data count for verification\n",
        "print(f\"Number of rows in aggregated data: {len(anova_df)}\")\n",
        "\n",
        "# 3-way ANOVA\n",
        "model = ols('Accuracy ~ C(Start_Type) * C(Trial_Type) * C(Image_Rating)', data=anova_df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(\"3-Way ANOVA Table:\")\n",
        "print(anova_table)\n",
        "\n",
        "# Extract degrees of freedom, F-statistic, and p-value\n",
        "for term, row in anova_table.iterrows():\n",
        "    df1 = int(row['df'])\n",
        "    df2 = int(anova_table['df'][term] + anova_table['df']['Residual'])\n",
        "    F = row['F']\n",
        "    p = row['PR(>F)']\n",
        "    print(f\"Term: {term}, F({df1}, {df2}) = {F:.2f}, p = {'< .001' if p < .001 else f'{p:.3f}'}\")\n",
        "\n",
        "# Tukey's HSD post hoc analysis\n",
        "mc = pairwise_tukeyhsd(anova_df['Accuracy'],\n",
        "                       anova_df['Start_Type'] + \"_\" + anova_df['Trial_Type'] + \"_\" + anova_df['Image_Rating'],\n",
        "                       alpha=0.05)\n",
        "\n",
        "print(\"\\nTukey's HSD post hoc test results:\")\n",
        "print(mc)\n",
        "\n",
        "# Save the aggregated data to the specified shared folder path\n",
        "datasave_folder_path = \"/content/drive/My Drive/Levy Lab/Value updating project/online analysis\"\n",
        "save_path = os.path.join(datasave_folder_path, \"aggregated_anova_data.csv\")\n",
        "\n",
        "anova_df.to_csv(save_path, index=False)\n",
        "print(f\"\\nAggregated data saved to {save_path}\")"
      ],
      "metadata": {
        "id": "dpRprAPRYozR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fitting sigmoid function to accuracy data for each condition\n",
        "\n",
        "To model within-block learning dynamics, a simple sigmoid function was fitted to the prediction accuracy data for each condition (defined by unique initial block identity, block type, and food item rating combinations). Before fitting, prediction accuracy data were averaged across subjects within each experimental condition. We then fit sigmoid curves to these group-averaged means to estimate the parameters L, k, and x0:\n",
        "\n",
        "y = L / (1 + e(−k*(x−x0))\n",
        "\n",
        "L represents the upper asymptote or threshold\n",
        "k is the growth rate\n",
        "x0 is the trial number at which prediction accuracy reaches half of L\n",
        "\n",
        "A two-sample t-test was performed to compare the learning rates between the start groups. Additionally, an ANOVA was conducted to compare the learning thresholds (L) across all conditions. Significant interactions of block type with start group and image item rating were identified and further analyzed using post hoc Tukey's HSD tests.\n"
      ],
      "metadata": {
        "id": "aev6iPksYqf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit\n",
        "import seaborn as sns\n",
        "\n",
        "# Define the simplified sigmoid function\n",
        "def sigmoid_function(x, L, k, x0):\n",
        "    return L / (1 + np.exp(-k * (x - x0)))\n",
        "\n",
        "def fix_block_numbering(df):\n",
        "    participants = df['Subject ID'].unique()\n",
        "    fixed_df_list = []\n",
        "\n",
        "    for participant in participants:\n",
        "        participant_df = df[df['Subject ID'] == participant].copy()\n",
        "        participant_df['Block Number'] = (participant_df['Trial type'] != participant_df['Trial type'].shift(1)).cumsum()\n",
        "        participant_df['Block'] = participant_df['Block Number'].astype(str) + \\\n",
        "                                  participant_df['Trial type'].apply(lambda x: 'C' if x == 'congruent' else 'I')\n",
        "        fixed_df_list.append(participant_df)\n",
        "\n",
        "    fixed_df = pd.concat(fixed_df_list, ignore_index=True)\n",
        "    return fixed_df\n",
        "\n",
        "# Function to analyze and compute averages for combined trials across all blocks for each collapsed rating\n",
        "def analyze_combined(data_df, collapsed_rating, start_type):\n",
        "    data_df = fix_block_numbering(data_df)\n",
        "    data_df['Simulated Trial Number'] = data_df.groupby(['Subject ID', 'Block', 'Collapsed Rating']).cumcount() + 1\n",
        "    data_df = data_df[data_df['Simulated Trial Number'] <= 9]\n",
        "    overall_avg = data_df[data_df['Collapsed Rating'] == collapsed_rating].groupby(['Trial type', 'Simulated Trial Number'])['Correct (Binary)'].agg(['mean', 'sem']).reset_index()\n",
        "    overall_avg['Start Type'] = start_type\n",
        "    overall_avg['Collapsed Rating'] = collapsed_rating\n",
        "    return overall_avg\n",
        "\n",
        "# Example data preparation before fitting and plotting (assuming `congruent_start_df` and `incongruent_start_df` are defined)\n",
        "congruent_liked = analyze_combined(congruent_start_df, 'Liked', 'Congruent Start')\n",
        "congruent_disliked = analyze_combined(congruent_start_df, 'Disliked', 'Congruent Start')\n",
        "incongruent_liked = analyze_combined(incongruent_start_df, 'Liked', 'Incongruent Start')\n",
        "incongruent_disliked = analyze_combined(incongruent_start_df, 'Disliked', 'Incongruent Start')\n",
        "\n",
        "# Consolidate all data\n",
        "consolidated_data = pd.concat([congruent_liked, congruent_disliked, incongruent_liked, incongruent_disliked])\n",
        "\n",
        "# Define color palettes for plotting\n",
        "paired_palette = sns.color_palette(\"Paired\")\n",
        "purple_palette = [paired_palette[8], paired_palette[9]]\n",
        "trial_palette = {\n",
        "    'Congruent start': paired_palette[7],  # Dark orange\n",
        "    'Incongruent start': paired_palette[6]  # Light orange\n",
        "}\n",
        "\n",
        "# Fit sigmoid curves and calculate residuals\n",
        "fit_results = {}\n",
        "residuals_dict = {}\n",
        "for (start_type, rating, trial_type), data in consolidated_data.groupby(['Start Type', 'Collapsed Rating', 'Trial type']):\n",
        "    initial_guesses = [0.8, 1.0, 1.0]  # L, k, x0 initial guesses\n",
        "    bounds = (0, [1.0, 5.0, 10.0])  # Bounds for L, k, and x0\n",
        "    popt, _ = curve_fit(sigmoid_function, data['Simulated Trial Number'], data['mean'], p0=initial_guesses, bounds=bounds, maxfev=2000)\n",
        "    fit_results[(start_type, rating, trial_type)] = popt\n",
        "\n",
        "    # Calculate residuals as the difference between fitted values and actual means\n",
        "    fitted_values = sigmoid_function(data['Simulated Trial Number'], *popt)\n",
        "    residuals = fitted_values - data['mean']\n",
        "    residuals_dict[(start_type, rating, trial_type)] = residuals\n",
        "\n",
        "# Plot results\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(24, 8))\n",
        "\n",
        "styles = {\n",
        "    ('Congruent Start', 'Liked', 'congruent'): {'color': purple_palette[1], 'marker': 'o', 'label': 'Liked, Congruent Trial', 'linestyle': '-', 'linewidth': 2.5},\n",
        "    ('Congruent Start', 'Liked', 'incongruent'): {'color': purple_palette[0], 'marker': 'o', 'label': 'Liked, Incongruent Trial', 'linestyle': '--', 'linewidth': 2.5},\n",
        "    ('Congruent Start', 'Disliked', 'congruent'): {'color': trial_palette['Congruent start'], 'marker': 'o', 'label': 'Disliked, Congruent Trial', 'linestyle': '-', 'linewidth': 2.5},\n",
        "    ('Congruent Start', 'Disliked', 'incongruent'): {'color': trial_palette['Incongruent start'], 'marker': 'o', 'label': 'Disliked, Incongruent Trial', 'linestyle': '--', 'linewidth': 2.5},\n",
        "    ('Incongruent Start', 'Liked', 'congruent'): {'color': purple_palette[1], 'marker': 'o', 'label': 'Liked, Congruent Trial', 'linestyle': '-', 'linewidth': 2.5},\n",
        "    ('Incongruent Start', 'Liked', 'incongruent'): {'color': purple_palette[0], 'marker': 'o', 'label': 'Liked, Incongruent Trial', 'linestyle': '--', 'linewidth': 2.5},\n",
        "    ('Incongruent Start', 'Disliked', 'congruent'): {'color': trial_palette['Congruent start'], 'marker': 'o', 'label': 'Disliked, Congruent Trial', 'linestyle': '-', 'linewidth': 2.5},\n",
        "    ('Incongruent Start', 'Disliked', 'incongruent'): {'color': trial_palette['Incongruent start'], 'marker': 'o', 'label': 'Disliked, Incongruent Trial', 'linestyle': '--', 'linewidth': 2.5}\n",
        "}\n",
        "\n",
        "for (start_type, rating, trial_type), data in consolidated_data.groupby(['Start Type', 'Collapsed Rating', 'Trial type']):\n",
        "    style = styles[(start_type, rating, trial_type)]\n",
        "    ax = axes[0] if start_type == 'Congruent Start' else axes[1]\n",
        "\n",
        "    # Plot residual error bars (one-sided: down if below fit, up if above fit)\n",
        "    residual_values = residuals_dict[(start_type, rating, trial_type)]\n",
        "    yerr_lower = np.where(residual_values > 0, np.abs(residual_values), 0)\n",
        "    yerr_upper = np.where(residual_values < 0, np.abs(residual_values), 0)\n",
        "    yerr = [yerr_upper, yerr_lower]\n",
        "    ax.errorbar(data['Simulated Trial Number'], data['mean'], yerr=yerr, fmt=style['marker'], label=style['label'], color=style['color'], linestyle='None', capsize=0)\n",
        "\n",
        "    # Plot fitted sigmoid curve\n",
        "    L, k, x0 = fit_results[(start_type, rating, trial_type)]\n",
        "    x_values = np.linspace(data['Simulated Trial Number'].min(), data['Simulated Trial Number'].max(), 100)\n",
        "    y_values = sigmoid_function(x_values, L, k, x0)\n",
        "    ax.plot(x_values, y_values, color=style['color'], linestyle=style['linestyle'], linewidth=style['linewidth'], label=f'Fit {style[\"label\"]}')\n",
        "\n",
        "# Annotate charts\n",
        "for i, (start_type, ax) in enumerate(zip(['Congruent Start', 'Incongruent Start'], axes)):\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.axhline(0.5, linestyle='--', color='grey', label='Chance Level')\n",
        "    n_size = n_congruent if start_type == 'Congruent Start' else n_incongruent\n",
        "    ax.set_title(f'{start_type} Subjects (n={n_size})', fontweight='bold')\n",
        "    ax.set_xlabel('Trial Number', fontweight='bold')\n",
        "    ax.set_ylabel('Average Accuracy' if i == 0 else '', fontweight='bold')\n",
        "    ax.grid(False)\n",
        "\n",
        "# Create a single legend to the right of the plots\n",
        "handles, labels = axes[1].get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5), title='Condition', title_fontsize='20', fontsize='18')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "plt.show()\n",
        "\n",
        "# Print fit results in a table format\n",
        "fit_results_df = pd.DataFrame(fit_results).T.reset_index()\n",
        "fit_results_df.columns = ['Start Type', 'Rating', 'Trial Type', 'L', 'k', 'x0']\n",
        "\n",
        "print(fit_results_df)"
      ],
      "metadata": {
        "id": "gKuTzTq3YrA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.stats import ttest_ind\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# Define the sigmoid function\n",
        "def sigmoid_function(x, L, k, x0):\n",
        "    return L / (1 + np.exp(-k * (x - x0)))\n",
        "\n",
        "# Function to fit sigmoid curves for each participant within each condition\n",
        "def fit_sigmoid_per_participant(df, start_condition, collapsed_rating, trial_type):\n",
        "    fit_results = []\n",
        "    for participant in df['Subject ID'].unique():\n",
        "        participant_data = df[(df['Subject ID'] == participant) &\n",
        "                              (df['Start Type'] == start_condition) &\n",
        "                              (df['Collapsed Rating'] == collapsed_rating) &\n",
        "                              (df['Trial type'] == trial_type)].copy()\n",
        "\n",
        "        # Create simulated trial numbers\n",
        "        participant_data['Simulated Trial Number'] = participant_data.groupby(['Subject ID', 'Block', 'Collapsed Rating']).cumcount() + 1\n",
        "        participant_data = participant_data[participant_data['Simulated Trial Number'] <= 9]\n",
        "\n",
        "        if len(participant_data) > 0:\n",
        "            x_data = participant_data['Simulated Trial Number']\n",
        "            y_data = participant_data['Correct (Binary)']\n",
        "            try:\n",
        "                popt, _ = curve_fit(sigmoid_function, x_data, y_data, bounds=(0, [1.0, 5.0, 10.0]), maxfev=2000)\n",
        "                L, k, x0 = popt\n",
        "                fit_results.append((participant, L, k, x0))\n",
        "            except RuntimeError:\n",
        "                # Handling convergence errors\n",
        "                continue\n",
        "    return fit_results\n",
        "\n",
        "# Prepare and fit the data\n",
        "def prepare_and_fit_data(all_participants_df):\n",
        "    # Make sure to copy the DataFrame to avoid modifications to original data\n",
        "    df = all_participants_df.copy()\n",
        "\n",
        "    # Convert 'Correct (Theoretical)' to binary\n",
        "    if 'Correct (Binary)' not in df.columns:\n",
        "        df['Correct (Binary)'] = df['Correct (Theoretical)'].astype(int)\n",
        "\n",
        "    # Collapse ratings into 'Liked' and 'Disliked' categories\n",
        "    def collapse_ratings(rating):\n",
        "        return 'Liked' if rating in ['strongly_like', 'like'] else 'Disliked'\n",
        "\n",
        "    df['Collapsed Rating'] = df['Image Rating'].apply(collapse_ratings)\n",
        "\n",
        "    # Rename 'aligned' and 'unaligned' to 'congruent' and 'incongruent'\n",
        "    df['Trial type'] = df['Trial type'].replace({'aligned': 'congruent', 'unaligned': 'incongruent'})\n",
        "\n",
        "    # Determine 'Start Type' for each participant\n",
        "    df['Start Type'] = df.groupby('Subject ID')['Trial type'].transform(lambda x: 'Congruent Start' if x.iloc[0] == 'congruent' else 'Incongruent Start')\n",
        "\n",
        "    # Fit sigmoid curves and collect results\n",
        "    conditions = [\n",
        "        ('Congruent Start', 'Liked', 'congruent'),\n",
        "        ('Congruent Start', 'Liked', 'incongruent'),\n",
        "        ('Congruent Start', 'Disliked', 'congruent'),\n",
        "        ('Congruent Start', 'Disliked', 'incongruent'),\n",
        "        ('Incongruent Start', 'Liked', 'congruent'),\n",
        "        ('Incongruent Start', 'Liked', 'incongruent'),\n",
        "        ('Incongruent Start', 'Disliked', 'congruent'),\n",
        "        ('Incongruent Start', 'Disliked', 'incongruent')\n",
        "    ]\n",
        "\n",
        "    all_fit_results = []\n",
        "    for start_condition, rating, trial_type in conditions:\n",
        "        fit_results = fit_sigmoid_per_participant(df, start_condition, rating, trial_type)\n",
        "        for participant, L, k, x0 in fit_results:\n",
        "            all_fit_results.append({\n",
        "                'Participant': participant,\n",
        "                'Start Type': start_condition,\n",
        "                'Rating': rating,\n",
        "                'Trial Type': trial_type,\n",
        "                'L': L,\n",
        "                'k': k,\n",
        "                'x0': x0\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(all_fit_results)\n",
        "\n",
        "# Extract and compare learning rates\n",
        "fit_results_df = prepare_and_fit_data(all_participants_df)\n",
        "\n",
        "# Make sure column names are consistently used\n",
        "fit_results_df.rename(columns={'Start Type': 'Start_Type', 'Trial Type': 'Trial_Type'}, inplace=True)\n",
        "\n",
        "# Extract learning rates for Congruent Start and Incongruent Start\n",
        "k_congruent_start = fit_results_df[fit_results_df['Start_Type'] == 'Congruent Start']['k']\n",
        "k_incongruent_start = fit_results_df[fit_results_df['Start_Type'] == 'Incongruent Start']['k']\n",
        "\n",
        "# Perform two-sample t-test\n",
        "t_stat, p_val = ttest_ind(k_congruent_start, k_incongruent_start)\n",
        "\n",
        "# Calculate and print the averages\n",
        "k_congruent_mean = np.mean(k_congruent_start)\n",
        "k_incongruent_mean = np.mean(k_incongruent_start)\n",
        "\n",
        "print(f\"Congruent Start average learning rate (k): {k_congruent_mean:.4f}\")\n",
        "print(f\"Incongruent Start average learning rate (k): {k_incongruent_mean:.4f}\")\n",
        "\n",
        "# Print the DataFrame\n",
        "print(fit_results_df)\n",
        "\n",
        "# Print the t-test results formatted for APA style reporting\n",
        "print(f\"T-test result for learning rates (k) comparison, t({len(k_congruent_start) + len(k_incongruent_start) - 2}) = {t_stat:.2f}, p = {p_val:.3f}\")\n",
        "\n",
        "# Perform ANOVA for thresholds (L)\n",
        "model_L = ols(\"L ~ C(Start_Type) * C(Rating) * C(Trial_Type)\", data=fit_results_df).fit()\n",
        "anova_table_L = sm.stats.anova_lm(model_L, typ=2)\n",
        "\n",
        "# Perform Tukey's HSD post hoc test for thresholds (L)\n",
        "tukey_L = pairwise_tukeyhsd(fit_results_df['L'], fit_results_df['Start_Type'] + \" - \" + fit_results_df['Rating'] + \" - \" + fit_results_df['Trial_Type'])\n",
        "\n",
        "# Print ANOVA table for Thresholds (L)\n",
        "print(\"ANOVA Table for Threshold (L):\")\n",
        "print(anova_table_L)\n",
        "\n",
        "# Print Tukey's HSD post hoc test results for Threshold (L)\n",
        "print(\"Tukey HSD Post Hoc Test for Threshold (L):\")\n",
        "print(tukey_L)\n",
        "\n",
        "# Display Tukey HSD plot for Threshold (L)\n",
        "fig = tukey_L.plot_simultaneous()\n",
        "plt.title(\"Tukey HSD Test for Threshold (L)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4pWLx5QMYt0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Assuming all_participants_df is already available and contains an 'Outcome' column\n",
        "# and 'Correct (Binary)' column for the binary accuracy is correctly set, we proceed:\n",
        "\n",
        "# Group by participant and then aggregate to find average accuracy per outcome type for each participant\n",
        "participant_accuracy = all_participants_df.groupby(['Subject ID', 'Outcome'])['Correct (Binary)'].mean().unstack()\n",
        "\n",
        "# Drop any rows with NaN values to ensure clean data\n",
        "participant_accuracy = participant_accuracy.dropna(subset=['positive', 'negative'])\n",
        "\n",
        "# Separate aggregated accuracy by outcome type\n",
        "positive_accuracy = participant_accuracy['positive']\n",
        "negative_accuracy = participant_accuracy['negative']\n",
        "\n",
        "# Debugging: Print the first few rows of participant_accuracy\n",
        "print(\"Participant Accuracy (First 5 Rows):\")\n",
        "print(participant_accuracy.head())\n",
        "\n",
        "# Debugging: Print summary statistics for positive_accuracy\n",
        "print(\"\\nPositive Accuracy Summary Statistics:\")\n",
        "print(positive_accuracy.describe())\n",
        "\n",
        "# Debugging: Print summary statistics for negative_accuracy\n",
        "print(\"\\nNegative Accuracy Summary Statistics:\")\n",
        "print(negative_accuracy.describe())\n",
        "\n",
        "# Perform Mann-Whitney U test on aggregated data\n",
        "u_statistic, p_value = mannwhitneyu(positive_accuracy, negative_accuracy, alternative='two-sided')\n",
        "\n",
        "# Calculate means for summary\n",
        "mean_positive = positive_accuracy.mean()\n",
        "mean_negative = negative_accuracy.mean()\n",
        "\n",
        "# Calculate standard deviations for summary\n",
        "std_positive = positive_accuracy.std()\n",
        "std_negative = negative_accuracy.std()\n",
        "\n",
        "# Compute ranksums and effect size\n",
        "n1 = len(positive_accuracy)\n",
        "n2 = len(negative_accuracy)\n",
        "\n",
        "# Effect size r\n",
        "effect_size = u_statistic / (n1 * n2)\n",
        "\n",
        "# Approximate the z-score\n",
        "z_score = (u_statistic - n1 * n2 / 2) / ((n1 * n2 * (n1 + n2 + 1) / 12) ** 0.5)\n",
        "\n",
        "# Debugging: Print sample sizes\n",
        "print(f\"Sample Size Positive Outcome: {n1}\")\n",
        "print(f\"Sample Size Negative Outcome: {n2}\")\n",
        "\n",
        "# Print results\n",
        "print(f\"U Statistic: {u_statistic}\")\n",
        "print(f\"Mean Positive Outcome: {mean_positive:.2f} ± {std_positive:.2f}\")\n",
        "print(f\"Mean Negative Outcome: {mean_negative:.2f} ± {std_negative:.2f}\")\n",
        "print(f\"Z Score: {z_score}\")\n",
        "print(f\"P Value: {p_value}\")\n",
        "print(f\"Effect Size: {effect_size}\")"
      ],
      "metadata": {
        "id": "Nk7h6A1PYvaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory: BES Global Scores and Accuracy\n",
        "\n",
        "Transformed average accuracy and BES Global Score data to rankit scores before performing Pearson correlation\n",
        "\n",
        "Regression controlling controlling for age, gender, and BMI"
      ],
      "metadata": {
        "id": "AgW3uFFbYzRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr, rankdata, norm\n",
        "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
        "\n",
        "# Path to the survey responses CSV file\n",
        "survey_responses_path = \"/content/drive/My Drive/Levy Lab/Value updating project/online analysis/subject data/survey_responses.csv\"\n",
        "\n",
        "# Load the survey responses CSV into a DataFrame with encoding specified\n",
        "survey_df = pd.read_csv(survey_responses_path, encoding='ISO-8859-1')\n",
        "\n",
        "# Transpose the survey data to make each subject's data a row\n",
        "survey_df = survey_df.transpose()\n",
        "\n",
        "# Set the first row as the header\n",
        "survey_df.columns = survey_df.iloc[0]\n",
        "survey_df = survey_df.drop(survey_df.index[0])\n",
        "\n",
        "# Convert columns to numeric where possible (except 'Subject ID')\n",
        "survey_df = survey_df.apply(pd.to_numeric, errors='ignore')\n",
        "\n",
        "# Preprocess accuracy data similarly to the previous analysis\n",
        "def preprocess_accuracy_data(data_df):\n",
        "    data_df['Image Rating'] = data_df['Image Rating'].replace({\n",
        "        'like': 'Liked items',\n",
        "        'strongly_like': 'Liked items',\n",
        "        'dislike': 'Disliked items',\n",
        "        'strongly_dislike': 'Disliked items'\n",
        "    })\n",
        "\n",
        "    data_df['Block Type'] = data_df['Block Type'].replace({\n",
        "        'Aligned': 'Congruent',\n",
        "        'Unaligned': 'Incongruent'\n",
        "    })\n",
        "\n",
        "    # Ensure 'Image Rating' and 'Block Type' are in the specified order\n",
        "    rating_order = ['Disliked items', 'Liked items']\n",
        "    data_df['Image Rating'] = pd.Categorical(data_df['Image Rating'], categories=rating_order, ordered=True)\n",
        "    block_order = ['Congruent', 'Incongruent']\n",
        "    data_df['Block Type'] = pd.Categorical(data_df['Block Type'], categories=block_order, ordered=True)\n",
        "\n",
        "    return data_df\n",
        "\n",
        "aligned_start_df = preprocess_accuracy_data(aligned_start_df)\n",
        "unaligned_start_df = preprocess_accuracy_data(unaligned_start_df)\n",
        "\n",
        "# Calculate mean accuracy by participant, block type, and image rating\n",
        "def compute_participant_means(data_df, block_type, rating_type):\n",
        "    grouped = data_df.groupby(['Subject ID', 'Block Type', 'Image Rating'], observed=False)['Correct (Binary)'].mean().reset_index()\n",
        "    return grouped[(grouped['Block Type'] == block_type) & (grouped['Image Rating'] == rating_type)]\n",
        "\n",
        "# Get mean accuracies for congruent start participants\n",
        "congruent_start_liked_df = compute_participant_means(aligned_start_df, 'Congruent', 'Liked items')\n",
        "congruent_start_disliked_df = compute_participant_means(aligned_start_df, 'Congruent', 'Disliked items')\n",
        "incongruent_start_liked_df = compute_participant_means(aligned_start_df, 'Incongruent', 'Liked items')\n",
        "incongruent_start_disliked_df = compute_participant_means(aligned_start_df, 'Incongruent', 'Disliked items')\n",
        "\n",
        "# Get mean accuracies for incongruent start participants\n",
        "congruent_start_liked_df_unaligned = compute_participant_means(unaligned_start_df, 'Congruent', 'Liked items')\n",
        "congruent_start_disliked_df_unaligned = compute_participant_means(unaligned_start_df, 'Congruent', 'Disliked items')\n",
        "incongruent_start_liked_df_unaligned = compute_participant_means(unaligned_start_df, 'Incongruent', 'Liked items')\n",
        "incongruent_start_disliked_df_unaligned = compute_participant_means(unaligned_start_df, 'Incongruent', 'Disliked items')\n",
        "\n",
        "# Merge accuracy data with survey data\n",
        "def merge_with_survey_data(participant_means_df, survey_df):\n",
        "    participant_means_df['Subject ID'] = participant_means_df['Subject ID'].astype(str)\n",
        "    merged_df = pd.merge(participant_means_df, survey_df, left_on='Subject ID', right_index=True)\n",
        "    return merged_df\n",
        "\n",
        "congruent_start_liked_merged = merge_with_survey_data(congruent_start_liked_df, survey_df)\n",
        "congruent_start_disliked_merged = merge_with_survey_data(congruent_start_disliked_df, survey_df)\n",
        "incongruent_start_liked_merged = merge_with_survey_data(incongruent_start_liked_df, survey_df)\n",
        "incongruent_start_disliked_merged = merge_with_survey_data(incongruent_start_disliked_df, survey_df)\n",
        "\n",
        "congruent_start_liked_merged_unaligned = merge_with_survey_data(congruent_start_liked_df_unaligned, survey_df)\n",
        "congruent_start_disliked_merged_unaligned = merge_with_survey_data(congruent_start_disliked_df_unaligned, survey_df)\n",
        "incongruent_start_liked_merged_unaligned = merge_with_survey_data(incongruent_start_liked_df_unaligned, survey_df)\n",
        "incongruent_start_disliked_merged_unaligned = merge_with_survey_data(incongruent_start_disliked_df_unaligned, survey_df)\n",
        "\n",
        "# Define custom colormap for BES Global scores\n",
        "colors = ['#FFCCCC', '#FF6666', '#CC0000']  # Colors for minimal, moderate, and severe BE\n",
        "cmap_name = 'category_reds'\n",
        "category_cmap = ListedColormap(colors)\n",
        "boundaries = [0, 18, 26, 46]\n",
        "norm_boundaries = BoundaryNorm(boundaries, category_cmap.N, clip=True)\n",
        "\n",
        "# Function to apply rank-based inverse normal transformation (rankit transformation)\n",
        "def rankit_transformation(series):\n",
        "    ranks = rankdata(series)\n",
        "    rankit_scores = norm.ppf((ranks - 0.5) / len(ranks))\n",
        "    return rankit_scores\n",
        "\n",
        "# Function to plot correlation between BES scores and mean accuracy by Block Type and Image Rating\n",
        "def plot_bes_accuracy_correlation(merged_df, block_type, image_rating, start_type):\n",
        "    bes_global = pd.to_numeric(merged_df['bes_GLOBAL'], errors='coerce')\n",
        "    mean_accuracy = pd.to_numeric(merged_df['Correct (Binary)'], errors='coerce')\n",
        "\n",
        "    # Drop NaN values\n",
        "    valid_indices = ~bes_global.isna() & ~mean_accuracy.isna()\n",
        "    bes_global = bes_global[valid_indices]\n",
        "    mean_accuracy = mean_accuracy[valid_indices]\n",
        "\n",
        "    # Apply rankit transformation to BES and mean accuracy\n",
        "    transformed_bes = rankit_transformation(bes_global)\n",
        "    transformed_mean_accuracy = rankit_transformation(mean_accuracy)\n",
        "\n",
        "    # Add a check to ensure transformed data have sufficient variance and are not constant\n",
        "    if np.std(transformed_bes) == 0 or np.std(transformed_mean_accuracy) == 0:\n",
        "        print(f\"Insufficient variance in transformed data for correlation between BES and mean accuracy for {start_type} Start - Block: {block_type} - Rating: {image_rating}\")\n",
        "        return\n",
        "\n",
        "    # If there are insufficient valid data points, skip plotting\n",
        "    if len(bes_global) < 2 or len(mean_accuracy) < 2:\n",
        "        print(f\"Insufficient data for correlation between BES and mean accuracy for {start_type} Start - Block: {block_type} - Rating: {image_rating}\")\n",
        "        return\n",
        "\n",
        "    correlation, p_value = pearsonr(transformed_bes, transformed_mean_accuracy)\n",
        "    df = len(bes_global) - 2  # Degrees of freedom\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    scatter = plt.scatter(transformed_bes, transformed_mean_accuracy, c=bes_global, cmap=category_cmap, norm=norm_boundaries, s=100, alpha=0.6)\n",
        "    plt.colorbar(scatter, label='BES Global')\n",
        "\n",
        "    sns.regplot(x=transformed_bes, y=transformed_mean_accuracy, scatter=False, line_kws={\"color\": \"pink\"}, ci=95)\n",
        "    plt.text(0.05, 0.95, f'r({df}) = {correlation:.3f}\\np = {p_value:.3f}', transform=plt.gca().transAxes, fontsize=12,\n",
        "             verticalalignment='top', bbox=dict(facecolor='white', alpha=0.6))\n",
        "\n",
        "    plt.title(f'Correlation Between BES Scores and Accuracy\\n({start_type} Start - Block: {block_type} - Rating: {image_rating})')\n",
        "    plt.xlabel('Transformed BES Scores')\n",
        "    plt.ylabel('Transformed Average Accuracy')\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "    print(f\"The Pearson correlation for {start_type} Start - Block: {block_type} - Rating: {image_rating} resulted in r({df}) = {correlation:.3f}, p = {p_value:.3f}.\")\n",
        "\n",
        "# Plot correlations for congruent start participants\n",
        "plot_bes_accuracy_correlation(congruent_start_liked_merged, 'Congruent', 'Liked items', 'Congruent')\n",
        "plot_bes_accuracy_correlation(congruent_start_disliked_merged, 'Congruent', 'Disliked items', 'Congruent')\n",
        "plot_bes_accuracy_correlation(incongruent_start_liked_merged, 'Incongruent', 'Liked items', 'Congruent')\n",
        "plot_bes_accuracy_correlation(incongruent_start_disliked_merged, 'Incongruent', 'Disliked items', 'Congruent')\n",
        "\n",
        "# Plot correlations for incongruent start participants\n",
        "plot_bes_accuracy_correlation(congruent_start_liked_merged_unaligned, 'Congruent', 'Liked items', 'Incongruent')\n",
        "plot_bes_accuracy_correlation(congruent_start_disliked_merged_unaligned, 'Congruent', 'Disliked items', 'Incongruent')\n",
        "plot_bes_accuracy_correlation(incongruent_start_liked_merged_unaligned, 'Incongruent', 'Liked items', 'Incongruent')\n",
        "plot_bes_accuracy_correlation(incongruent_start_disliked_merged_unaligned, 'Incongruent', 'Disliked items', 'Incongruent')"
      ],
      "metadata": {
        "id": "a1YPHUavYz2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
        "\n",
        "# Define custom colormap for BES Global scores in purple shades\n",
        "colors = ['#E5CCFF', '#B266FF', '#6600CC']  # Colors for minimal, moderate, and severe BE\n",
        "cmap_name = 'category_purples'\n",
        "category_cmap = ListedColormap(colors)\n",
        "boundaries = [0, 18, 26, 46]\n",
        "norm_boundaries = BoundaryNorm(boundaries, category_cmap.N, clip=True)\n",
        "\n",
        "# Filter the dataframe for the specific condition\n",
        "filtered_df = incongruent_start_disliked_merged.copy()\n",
        "\n",
        "# Verify specific columns' data types\n",
        "relevant_columns = ['bes_GLOBAL', 'survey_age', 'survey_gender', 'BMI', 'Correct (Binary)']\n",
        "filtered_df = filtered_df[relevant_columns]\n",
        "\n",
        "# Debug check\n",
        "print(\"Relevant DataFrame:\\n\", filtered_df.head())\n",
        "\n",
        "# Convert specific columns to the appropriate numeric types\n",
        "for col in ['bes_GLOBAL', 'survey_age', 'BMI', 'Correct (Binary)']:\n",
        "    filtered_df[col] = pd.to_numeric(filtered_df[col], errors='coerce')\n",
        "\n",
        "# Debug check after numeric conversion\n",
        "print(\"DataFrame after numeric conversion:\\n\", filtered_df.head())\n",
        "\n",
        "# Drop rows with any missing values\n",
        "filtered_df = filtered_df.dropna()\n",
        "\n",
        "# Debug check after dropping NaNs\n",
        "print(\"DataFrame after dropping NaNs:\\n\", filtered_df.head())\n",
        "\n",
        "# Confirm DataFrame size to ensure it is not empty\n",
        "print(\"DataFrame shape after processing:\", filtered_df.shape)\n",
        "if filtered_df.empty:\n",
        "    raise ValueError(\"The processed DataFrame is empty. Please check your data.\")\n",
        "\n",
        "# Select relevant columns for regression analysis\n",
        "X = filtered_df[['bes_GLOBAL', 'survey_age', 'survey_gender', 'BMI']]\n",
        "y = filtered_df['Correct (Binary)']\n",
        "\n",
        "# Convert categorical columns to categories and then to dummy variables\n",
        "X = pd.get_dummies(X, columns=['survey_gender'], drop_first=True)\n",
        "\n",
        "# Ensure all dummy variables are integer\n",
        "X = X.apply(lambda col: col.astype(np.float64) if col.dtype == bool else col)\n",
        "\n",
        "# Debug check after dummy encoding and conversion\n",
        "print(\"X after dummy encoding and conversion:\\n\", X.head())\n",
        "print(X.dtypes)\n",
        "\n",
        "# Add a constant to the model (intercept)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Convert all columns to float or appropriate numeric types\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Debug check after ensuring all numeric types\n",
        "print(X.dtypes)\n",
        "print(y.dtypes)\n",
        "\n",
        "# Fit the linear regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the summary of the regression model\n",
        "print(model.summary())\n",
        "\n",
        "# Extract R-squared and p-value for the bes_GLOBAL variable\n",
        "r_squared = model.rsquared\n",
        "p_value_bes_GLOBAL = model.pvalues['bes_GLOBAL']\n",
        "\n",
        "# Print R-squared and p-value for verification\n",
        "print(f\"R-squared: {r_squared}\")\n",
        "print(f\"P-value (bes_GLOBAL): {p_value_bes_GLOBAL}\")\n",
        "\n",
        "# Predict the values\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Residuals\n",
        "residuals = y - predictions\n",
        "\n",
        "# Plot the correlation between BES scores and accuracy, controlling for other variables\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "# Scatter plot and regression\n",
        "scatter = axes[0].scatter(filtered_df['bes_GLOBAL'], y, c=filtered_df['bes_GLOBAL'], cmap=category_cmap, norm=norm_boundaries, s=100, alpha=0.6)\n",
        "sns.regplot(x=filtered_df['bes_GLOBAL'], y=y, scatter=False, line_kws={\"color\": \"purple\"}, ci=95, ax=axes[0])\n",
        "plt.colorbar(scatter, ax=axes[0], label='BES Global')\n",
        "axes[0].set_title(\"Regression Analysis: Congruent-Start Participants \\nBES Scores vs Incongruent Block, Disliked Accuracy \\nControlling for Age, Gender, and BMI\", fontsize=16, fontweight='bold')\n",
        "axes[0].set_xlabel('Global BES Scores', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('Average Accuracy', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Annotate with both R-squared and p-value in the same box\n",
        "annotation_text = f'R-squared: {r_squared:.2f}\\nP-value (BES Global Score): {p_value_bes_GLOBAL:.3f}'\n",
        "axes[0].annotate(annotation_text, xy=(0.05, 0.01), xycoords='axes fraction', fontsize=14, ha='left', va='bottom',\n",
        "                 bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='grey', facecolor='white'))\n",
        "\n",
        "# Residuals plot\n",
        "axes[1].scatter(predictions, residuals, c='purple', alpha=0.6)\n",
        "axes[1].axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
        "axes[1].set_title('Residuals Plot', fontsize=16, fontweight='bold')\n",
        "axes[1].set_xlabel('Average Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('Residuals', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y_BDlY9DY2KB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}