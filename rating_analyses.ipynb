{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21bf163e",
   "metadata": {},
   "source": [
    "# Rating analyses (pre task) for all recruited participants (N=415)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2b7ae",
   "metadata": {},
   "source": [
    "## Heterogeneity across items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Access the shared folder\n",
    "shared_folder_path = \"\"\n",
    "\n",
    "# Collate ratings for each food item\n",
    "ratings = {}\n",
    "\n",
    "# Iterate through each subject folder\n",
    "for subject_folder in os.listdir(shared_folder_path):\n",
    "    subject_folder_path = os.path.join(shared_folder_path, subject_folder)\n",
    "\n",
    "    # Check if the item is a directory (subject folder)\n",
    "    if os.path.isdir(subject_folder_path):\n",
    "        # Construct the path to the ratings CSV file (e.g., 654_ratings.csv)\n",
    "        task_file_name = f\"{subject_folder}_ratings.csv\"\n",
    "        task_file_path = os.path.join(subject_folder_path, task_file_name)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(task_file_path):\n",
    "            # Read the task CSV file into a DataFrame\n",
    "            df = pd.read_csv(task_file_path)\n",
    "\n",
    "            # Append ratings to the ratings dictionary\n",
    "            for index, row in df.iterrows():\n",
    "                image = row['image']\n",
    "                response = row['response']\n",
    "                if pd.notna(image):  # Ensure 'image' is not NaN\n",
    "                    if image in ratings:\n",
    "                        ratings[image].append(response)\n",
    "                    else:\n",
    "                        ratings[image] = [response]\n",
    "        else:\n",
    "            print(f\"No data found for participant {subject_folder}.\")\n",
    "\n",
    "# Ensure there is data\n",
    "if not ratings:\n",
    "    print(\"No ratings data found.\")\n",
    "else:\n",
    "    # Calculate the average rating and SD for each food item\n",
    "    average_ratings = {image: sum(responses) / len(responses) for image, responses in ratings.items()}\n",
    "    sd_ratings = {image: np.std(responses, ddof=1) for image, responses in ratings.items()}\n",
    "\n",
    "    # Sort the average ratings in ascending order\n",
    "    sorted_ratings = sorted(average_ratings.items(), key=lambda x: x[1])\n",
    "\n",
    "    # Separate the data for plotting\n",
    "    food_items = [item[0] for item in sorted_ratings]\n",
    "    average_ratings_values = [item[1] for item in sorted_ratings]\n",
    "    sd_values = [sd_ratings[item[0]] for item in sorted_ratings]\n",
    "\n",
    "    # Create a scatter plot with improved aesthetics\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.errorbar(range(len(food_items)), average_ratings_values, yerr=sd_values, fmt='o', color='steelblue', ecolor='lightgrey', elinewidth=3, capsize=0)  # light blue color with error bars\n",
    "    plt.xticks(range(len(food_items)), food_items, rotation='vertical', fontsize=14)  # Increased fontsize for xticks\n",
    "\n",
    "    # Improved label spacing to avoid overlap\n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "    # Bold and increase size of axes titles and main title\n",
    "    plt.xlabel('Food Items', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Average Rating', fontsize=16, fontweight='bold')\n",
    "    plt.title('Average Rating for Each Food Item with SD', fontsize=18, fontweight='bold')\n",
    "\n",
    "    # Remove grid lines for a cleaner look\n",
    "    plt.grid(False)\n",
    "\n",
    "    # Specify y-axis min and max values to avoid the wonky presets\n",
    "    y_min = 1 \n",
    "    y_max = 5  \n",
    "    y_step = 1  \n",
    "    plt.ylim([y_min, y_max])\n",
    "    plt.yticks(range(y_min, y_max + 1, y_step), fontsize=16)  \n",
    "\n",
    "    # Ensure layout is tight for better spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96538c53",
   "metadata": {},
   "source": [
    "## Correlation with caloric and nutritional content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "nutrition_info_path = \"\" #this is data obtained with Columbia FoodFolio stimuli set \n",
    "\n",
    "# Read the nutritional information\n",
    "nutrition_df = pd.read_csv(nutrition_info_path)\n",
    "\n",
    "# Merge the average ratings with nutritional data\n",
    "merged_df = pd.merge(average_ratings_df, nutrition_df, on='Food Image')\n",
    "\n",
    "spearman_corr, spearman_p_value = spearmanr(merged_df['Average Rating'], merged_df['Total Calories'])\n",
    "\n",
    "# Plot Spearman correlation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='Total Calories', y='Average Rating', data=merged_df, scatter_kws={'s': 100, 'color': 'steelblue', 'edgecolor': 'w'}, line_kws={'color': 'grey'})  # Add regression line\n",
    "plt.title('Food Likert Ratings and Caloric Content', fontsize=16, weight='bold')\n",
    "plt.xlabel('Total Calories', fontsize=14, weight='bold')\n",
    "plt.ylabel('Average Rating', fontsize=14, weight='bold')\n",
    "plt.text(0.5, 0.87,\n",
    "         f'Spearman Correlation: {spearman_corr:.2f}\\nP-value: {spearman_p_value:.4f}',\n",
    "         fontsize=12, bbox=dict(facecolor='white', alpha=0.5),\n",
    "         ha='center', transform=plt.gca().transAxes)  # Centered text overlay below title\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_linewidth(1.5)\n",
    "plt.gca().spines['bottom'].set_linewidth(1.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df442914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearman_corr, spearman_p_value = spearmanr(merged_df['Average Rating'], merged_df['Fat (g)'])\n",
    "\n",
    "# Plot Spearman correlation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='Fat (g)', y='Average Rating', data=merged_df, scatter_kws={'s': 100, 'color': 'steelblue', 'edgecolor': 'w'}, line_kws={'color': 'grey'})  # Add regression line\n",
    "plt.title('Food Likert Ratings and Fat Content', fontsize=16, weight='bold')\n",
    "plt.xlabel('Fat (g)', fontsize=14, weight='bold')\n",
    "plt.ylabel('Average Rating', fontsize=14, weight='bold')\n",
    "plt.text(0.5, 0.87,\n",
    "         f'Spearman Correlation: {spearman_corr:.2f}\\nP-value: {spearman_p_value:.4f}',\n",
    "         fontsize=12, bbox=dict(facecolor='white', alpha=0.5),\n",
    "         ha='center', transform=plt.gca().transAxes)  # Centered text overlay below title\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_linewidth(1.5)\n",
    "plt.gca().spines['bottom'].set_linewidth(1.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11863c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "spearman_corr, spearman_p_value = spearmanr(merged_df['Average Rating'], merged_df['Protein (g)'])\n",
    "\n",
    "# Plot Spearman correlation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='Protein (g)', y='Average Rating', data=merged_df, scatter_kws={'s': 100, 'color': 'steelblue', 'edgecolor': 'w'}, line_kws={'color': 'grey'})  # Add regression line\n",
    "plt.title('Food Likert Ratings and Protein Content', fontsize=16, weight='bold')\n",
    "plt.xlabel('Protein (g)', fontsize=14, weight='bold')\n",
    "plt.ylabel('Average Rating', fontsize=14, weight='bold')\n",
    "plt.text(0.5, 0.87,\n",
    "         f'Spearman Correlation: {spearman_corr:.2f}\\nP-value: {spearman_p_value:.4f}',\n",
    "         fontsize=12, bbox=dict(facecolor='white', alpha=0.5),\n",
    "         ha='center', transform=plt.gca().transAxes)  # Centered text overlay below title\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_linewidth(1.5)\n",
    "plt.gca().spines['bottom'].set_linewidth(1.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "spearman_corr, spearman_p_value = spearmanr(merged_df['Average Rating'], merged_df['Carbohydrate (g)'])\n",
    "\n",
    "# Plot Spearman correlation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='Carbohydrate (g)', y='Average Rating', data=merged_df, scatter_kws={'s': 100, 'color': 'steelblue', 'edgecolor': 'w'}, line_kws={'color': 'grey'})  # Add regression line\n",
    "plt.title('Food Likert Ratings and Carbohydrate Content', fontsize=16, weight='bold')\n",
    "plt.xlabel('Carbohydrate (g)', fontsize=14, weight='bold')\n",
    "plt.ylabel('Average Rating', fontsize=14, weight='bold')\n",
    "plt.text(0.5, 0.87,\n",
    "         f'Spearman Correlation: {spearman_corr:.2f}\\nP-value: {spearman_p_value:.4f}',\n",
    "         fontsize=12, bbox=dict(facecolor='white', alpha=0.5),\n",
    "         ha='center', transform=plt.gca().transAxes)  # Centered text overlay below title\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_linewidth(1.5)\n",
    "plt.gca().spines['bottom'].set_linewidth(1.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c5eec",
   "metadata": {},
   "source": [
    "# Preparing the data for pre/post task rating analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Access the shared folder\n",
    "shared_folder_path = \"\"\n",
    "\n",
    "# Dictionary to hold DataFrames for each participant\n",
    "participant_data = {}\n",
    "participants_without_data = []\n",
    "\n",
    "# Iterate through each subject folder\n",
    "for subject_folder in os.listdir(shared_folder_path):\n",
    "    subject_folder_path = os.path.join(shared_folder_path, subject_folder)\n",
    "\n",
    "    # Check if the item is a directory (subject folder)\n",
    "    if os.path.isdir(subject_folder_path):\n",
    "        # Construct the path to the ratings CSV file (e.g., 654_ratings.csv)\n",
    "        task_file_name = f\"{subject_folder}_subset_ratings_post.csv\"\n",
    "        task_file_path = os.path.join(subject_folder_path, task_file_name)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(task_file_path):\n",
    "            # Read the task CSV file into a DataFrame\n",
    "            df = pd.read_csv(task_file_path)\n",
    "\n",
    "            # Store the DataFrame in the dictionary with the subject ID as the key\n",
    "            participant_data[subject_folder] = df\n",
    "            #print(f\"Data loaded successfully for participant {subject_folder}.\")\n",
    "        else:\n",
    "            participants_without_data.append(subject_folder)\n",
    "            print(f\"No data found for participant {subject_folder}.\")\n",
    "\n",
    "# Report the number of participants\n",
    "total_participants = len(participant_data) + len(participants_without_data)\n",
    "print(f\"\\nTotal participants processed: {total_participants}\")\n",
    "\n",
    "# Final message based on loading status\n",
    "if not participants_without_data:\n",
    "    print(\"Data loaded successfully for all participants.\")\n",
    "else:\n",
    "    print(\"Some participants did not have data loaded:\")\n",
    "    for participant in participants_without_data:\n",
    "        print(f\"- {participant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8431459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Access the shared folder\n",
    "shared_folder_path = \"/Users/alexrich/Documents/onlinedata_fullsample\"\n",
    "\n",
    "# Dictionary to hold DataFrames for each participant\n",
    "participant_data = {}\n",
    "participants_without_data = []\n",
    "\n",
    "# Iterate through each subject folder\n",
    "for subject_folder in os.listdir(shared_folder_path):\n",
    "    subject_folder_path = os.path.join(shared_folder_path, subject_folder)\n",
    "\n",
    "    # Check if the item is a directory (subject folder)\n",
    "    if os.path.isdir(subject_folder_path):\n",
    "        \n",
    "        # Construct the paths to the ratings files\n",
    "        pre_file_name = f\"{subject_folder}_subset_ratings_pre.csv\"\n",
    "        post_file_name = f\"{subject_folder}_subset_ratings_post.csv\"\n",
    "        ratings_file_name = f\"{subject_folder}_ratings.csv\"\n",
    "        \n",
    "        pre_file_path = os.path.join(subject_folder_path, pre_file_name)\n",
    "        post_file_path = os.path.join(subject_folder_path, post_file_name)\n",
    "        ratings_file_path = os.path.join(subject_folder_path, ratings_file_name)\n",
    "\n",
    "        # Check if the files exist\n",
    "        if os.path.exists(pre_file_path) and os.path.exists(post_file_path) and os.path.exists(ratings_file_path):\n",
    "            # Read the task CSV files into DataFrames\n",
    "            df_pre = pd.read_csv(pre_file_path)\n",
    "            df_post = pd.read_csv(post_file_path)\n",
    "            df_ratings = pd.read_csv(ratings_file_path)\n",
    "            \n",
    "            # Debug statements to confirm file loading\n",
    "            print(f\"Loaded pre data for participant {subject_folder}:\")\n",
    "            print(df_pre.head())\n",
    "            print(f\"Loaded post data for participant {subject_folder}:\")\n",
    "            print(df_post.head())\n",
    "            \n",
    "            # Merge 'rating' from df_ratings into df_pre and df_post based on 'image'\n",
    "            df_pre = df_pre.merge(df_ratings[['image', 'response']], on='image', how='left')\n",
    "            df_pre.rename(columns={'response': 'rating'}, inplace=True)\n",
    "            \n",
    "            df_post = df_post.merge(df_ratings[['image', 'response']], on='image', how='left')\n",
    "            df_post.rename(columns={'response': 'rating'}, inplace=True)\n",
    "            \n",
    "            # Debug statements to confirm merging\n",
    "            print(f\"Pre data with ratings for participant {subject_folder}:\")\n",
    "            print(df_pre.head())\n",
    "            print(f\"Post data with ratings for participant {subject_folder}:\")\n",
    "            print(df_post.head())\n",
    "            \n",
    "            # Store the modified DataFrames back to the files\n",
    "            df_pre.to_csv(pre_file_path, index=False)\n",
    "            df_post.to_csv(post_file_path, index=False)\n",
    "            \n",
    "            # Store the DataFrames in the dictionary with the subject ID as the key\n",
    "            participant_data[subject_folder] = {'pre': df_pre, 'post': df_post}\n",
    "            # Print success message for participant\n",
    "            print(f\"Data loaded and saved successfully for participant {subject_folder}.\")\n",
    "\n",
    "        else:\n",
    "            participants_without_data.append(subject_folder)\n",
    "            print(f\"No data found for participant {subject_folder}.\")\n",
    "\n",
    "# Report the number of participants\n",
    "total_participants = len(participant_data) + len(participants_without_data)\n",
    "print(f\"\\nTotal participants processed: {total_participants}\")\n",
    "\n",
    "# Final message based on loading status\n",
    "if not participants_without_data:\n",
    "    print(\"Data loaded successfully for all participants.\")\n",
    "else:\n",
    "    print(\"Some participants did not have data loaded:\")\n",
    "    for participant in participants_without_data:\n",
    "        print(f\"- {participant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast  # For converting strings to dictionaries\n",
    "\n",
    "# Access the shared folder\n",
    "shared_folder_path = \"\"\n",
    "\n",
    "# Function to parse the 'response_x' column into separate columns\n",
    "def parse_response_column(df, column_name='response_x'):\n",
    "    parsed_df = df.copy()\n",
    "    \n",
    "    # Convert the 'response_x' JSON string to separate columns\n",
    "    def parse_json(row):\n",
    "        try:\n",
    "            response_dict = ast.literal_eval(row)\n",
    "            return pd.Series(response_dict)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return pd.Series({\"paying\": None, \"enjoyable\": None, \"satisfaction\": None})\n",
    "    \n",
    "    if column_name in parsed_df.columns:\n",
    "        parsed_columns = parsed_df[column_name].apply(parse_json)\n",
    "        # Assign parsed columns to the DataFrame\n",
    "        parsed_df = parsed_df.join(parsed_columns)\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
    "    \n",
    "    return parsed_df\n",
    "\n",
    "# Iterate through each subject folder\n",
    "for subject_folder in os.listdir(shared_folder_path):\n",
    "    subject_folder_path = os.path.join(shared_folder_path, subject_folder)\n",
    "    \n",
    "    # Check if the item is a directory (subject folder)\n",
    "    if os.path.isdir(subject_folder_path):\n",
    "        try:\n",
    "            # Construct the paths to the ratings files\n",
    "            pre_file_name = f\"{subject_folder}_subset_ratings_pre.csv\"\n",
    "            post_file_name = f\"{subject_folder}_subset_ratings_post.csv\"\n",
    "            \n",
    "            pre_file_path = os.path.join(subject_folder_path, pre_file_name)\n",
    "            post_file_path = os.path.join(subject_folder_path, post_file_name)\n",
    "\n",
    "            # Processing pre file if exists\n",
    "            if os.path.exists(pre_file_path):\n",
    "                print(f\"Processing 'pre' data for participant {subject_folder}\")\n",
    "                # Read the pre CSV file into a DataFrame\n",
    "                df_pre = pd.read_csv(pre_file_path)\n",
    "                \n",
    "                # Check if parsed columns already exist\n",
    "                if 'paying' not in df_pre.columns or 'enjoyable' not in df_pre.columns or 'satisfaction' not in df_pre.columns:\n",
    "                    # Parse the 'response_x' column into separate columns\n",
    "                    df_pre = parse_response_column(df_pre)\n",
    "                    \n",
    "                    # Store the modified DataFrame back to the file\n",
    "                    df_pre.to_csv(pre_file_path, index=False)\n",
    "                    \n",
    "                    print(f\"Pre data parsed and saved successfully for participant {subject_folder}.\")\n",
    "                else:\n",
    "                    print(f\"Pre data for participant {subject_folder} already has parsed columns.\")\n",
    "            \n",
    "            # Processing post file if exists\n",
    "            if os.path.exists(post_file_path):\n",
    "                print(f\"Processing 'post' data for participant {subject_folder}\")\n",
    "                # Read the post CSV file into a DataFrame\n",
    "                df_post = pd.read_csv(post_file_path)\n",
    "                \n",
    "                # Check if parsed columns already exist\n",
    "                if 'paying' not in df_post.columns or 'enjoyable' not in df_post.columns or 'satisfaction' not in df_post.columns:\n",
    "                    # Parse the 'response_x' column into separate columns\n",
    "                    df_post = parse_response_column(df_post)\n",
    "                    \n",
    "                    # Store the modified DataFrame back to the file\n",
    "                    df_post.to_csv(post_file_path, index=False)\n",
    "                    \n",
    "                    print(f\"Post data parsed and saved successfully for participant {subject_folder}.\")\n",
    "                else:\n",
    "                    print(f\"Post data for participant {subject_folder} already has parsed columns.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing participant {subject_folder}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e269327e",
   "metadata": {},
   "source": [
    "# Pre-post task for task-eligible participants (n=279): changes in subjective valuation measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed64333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "import seaborn as sns\n",
    "\n",
    "# will print significant t test results and plot pre/post ratings for both start groups, for each of the 3 subjective value scales (willingness to pay, enjoyability, satisfaction)\n",
    "\n",
    "# Function to calculate statistics and t-tests\n",
    "def calculate_statistics(pre_data, post_data):\n",
    "    avg_pre = {key: np.mean(values) if values else None for key, values in pre_data.items()}\n",
    "    avg_post = {key: np.mean(values) if values else None for key, values in post_data.items()}\n",
    "    std_pre = {key: np.std(values) / np.sqrt(len(values)) if values else None for key, values in pre_data.items()}\n",
    "    std_post = {key: np.std(values) / np.sqrt(len(values)) if values else None for key, values in post_data.items()}\n",
    "\n",
    "    p_values = {}\n",
    "    t_stats = {}\n",
    "    dfs = {}  # Store degrees of freedom\n",
    "    for key in pre_data.keys():\n",
    "        p_values[key] = None\n",
    "        t_stats[key] = None\n",
    "        dfs[key] = None\n",
    "        if pre_data[key] and post_data[key]:\n",
    "            t_stat, p_value = ttest_rel(pre_data[key], post_data[key])\n",
    "            p_values[key] = p_value\n",
    "            t_stats[key] = t_stat\n",
    "            dfs[key] = len(pre_data[key]) - 1  # Degrees of freedom\n",
    "\n",
    "    return avg_pre, avg_post, std_pre, std_post, p_values, t_stats, dfs\n",
    "\n",
    "# Function for processing data\n",
    "def process_data(subject_folder_path, pre_file_name, post_file_name, response_column, measure_column):\n",
    "    pre_congruent = {'Disliked': [], 'Liked': []}\n",
    "    post_congruent = {'Disliked': [], 'Liked': []}\n",
    "    pre_incongruent = {'Disliked': [], 'Liked': []}\n",
    "    post_incongruent = {'Disliked': [], 'Liked': []}\n",
    "\n",
    "    for subject_folder in os.listdir(subject_folder_path):\n",
    "        subject_path = os.path.join(subject_folder_path, subject_folder)\n",
    "        if os.path.isdir(subject_path):\n",
    "            pre_file_path = os.path.join(subject_path, f\"{subject_folder}_{pre_file_name}\")\n",
    "            post_file_path = os.path.join(subject_path, f\"{subject_folder}_{post_file_name}\")\n",
    "\n",
    "            if not all([os.path.exists(pre_file_path), os.path.exists(post_file_path)]):\n",
    "                continue\n",
    "\n",
    "            starting_block = None\n",
    "            task_file_path = os.path.join(subject_path, f\"{subject_folder}_task.csv\")\n",
    "            if os.path.exists(task_file_path):\n",
    "                df_task = pd.read_csv(task_file_path)\n",
    "                if 'Trial type' in df_task.columns and not df_task.empty:\n",
    "                    starting_block = df_task['Trial type'].iloc[0]\n",
    "\n",
    "            if starting_block not in ['aligned', 'unaligned']:\n",
    "                continue\n",
    "\n",
    "            pre_data = pre_congruent if starting_block == 'aligned' else pre_incongruent\n",
    "            post_data = post_congruent if starting_block == 'aligned' else post_incongruent\n",
    "\n",
    "            # Pre data processing\n",
    "            df_pre = pd.read_csv(pre_file_path)\n",
    "            if measure_column in df_pre.columns and response_column in df_pre.columns:\n",
    "                for response_y in [1.0, 2.0, 4.0, 5.0]:\n",
    "                    key = 'Disliked' if response_y in [1.0, 2.0] else 'Liked'\n",
    "                    values = df_pre[df_pre[response_column] == response_y][measure_column].astype(float).tolist()\n",
    "                    pre_data[key].extend(values)\n",
    "\n",
    "            # Post data processing\n",
    "            df_post = pd.read_csv(post_file_path)\n",
    "            if measure_column in df_post.columns and response_column in df_post.columns:\n",
    "                for response_y in [1.0, 2.0, 4.0, 5.0]:\n",
    "                    key = 'Disliked' if response_y in [1.0, 2.0] else 'Liked'\n",
    "                    values = df_post[df_post[response_column] == response_y][measure_column].astype(float).tolist()\n",
    "                    post_data[key].extend(values)\n",
    "\n",
    "    return pre_congruent, post_congruent, pre_incongruent, post_incongruent\n",
    "\n",
    "# Data directory and file names\n",
    "shared_folder_path = \"/Users/alexrich/Documents/onlinedata_fullsample\"\n",
    "response_column = 'response_y'\n",
    "\n",
    "# Measure columns and titles for the plots to be generated\n",
    "measures = [\n",
    "    {'measure_column': 'paying', 'pre_file_name': 'subset_ratings_pre.csv', 'post_file_name': 'subset_ratings_post.csv', 'ylabel': 'Average Willingness to Pay ($)', 'title': 'Willingness to Pay'},\n",
    "    {'measure_column': 'enjoyable', 'pre_file_name': 'subset_ratings_pre.csv', 'post_file_name': 'subset_ratings_post.csv', 'ylabel': 'Average \"Enjoyable\" Rating', 'title': 'Enjoyable'},\n",
    "    {'measure_column': 'satisfaction', 'pre_file_name': 'subset_ratings_pre.csv', 'post_file_name': 'subset_ratings_post.csv', 'ylabel': 'Average \"Satisfaction\" Rating', 'title': 'Satisfaction'}\n",
    "]\n",
    "\n",
    "# Function to plot results\n",
    "def plot_measure_results(ax, avg_pre, avg_post, std_pre, std_post, p_values, t_stats, dfs, response_labels, ylabel, title):\n",
    "    pre_values = [avg_pre[key] for key in response_labels]\n",
    "    post_values = [avg_post[key] for key in response_labels]\n",
    "    pre_errors = [std_pre[key] for key in response_labels]\n",
    "    post_errors = [std_post[key] for key in response_labels]\n",
    "\n",
    "    paired_palette = sns.color_palette(\"Paired\")\n",
    "    colors = {\n",
    "        'Disliked_pre': paired_palette[6],\n",
    "        'Disliked_post': paired_palette[7],\n",
    "        'Liked_pre': paired_palette[8],\n",
    "        'Liked_post': paired_palette[9],\n",
    "    }\n",
    "    \n",
    "    x = np.arange(len(response_labels))\n",
    "    width = 0.35\n",
    "\n",
    "    rects1 = ax.bar(x - width/2, pre_values, width, label='Pre', color=[colors[f'{label}_pre'] for label in response_labels], yerr=pre_errors, capsize=5)\n",
    "    rects2 = ax.bar(x + width/2, post_values, width, label='Post', color=[colors[f'{label}_post'] for label in response_labels], yerr=post_errors, capsize=5)\n",
    "\n",
    "    # Add significance stars and print significant t-tests in APA format\n",
    "    for i, key in enumerate(response_labels):\n",
    "        if p_values[key] is not None:\n",
    "            significance = \"\"\n",
    "            if p_values[key] < 0.001:\n",
    "                significance = \"***\"\n",
    "                print(f\"{title} ({key}): t({dfs[key]}) = {t_stats[key]:.2f}, p < .001\")\n",
    "            elif p_values[key] < 0.01:\n",
    "                significance = \"**\"\n",
    "                print(f\"{title} ({key}): t({dfs[key]}) = {t_stats[key]:.2f}, p = {p_values[key]:.3f}\")\n",
    "            elif p_values[key] < 0.05:\n",
    "                significance = \"*\"\n",
    "                print(f\"{title} ({key}): t({dfs[key]}) = {t_stats[key]:.2f}, p = {p_values[key]:.3f}\")\n",
    "            if significance:\n",
    "                ax.text(i, max(pre_values[i] + pre_errors[i], post_values[i] + post_errors[i]) + 0.1,\n",
    "                        significance, ha='center', va='bottom', fontsize=20, color='black')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_xlabel('Food Item Rating', fontsize=20, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=22, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(response_labels)\n",
    "\n",
    "    # Increase font size of tick labels\n",
    "    ax.tick_params(axis='both', which='major', labelsize=19)\n",
    "\n",
    "    # Remove grid lines\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Set y-axis maximum\n",
    "    ax.set_ylim([0, 5])\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 24), constrained_layout=True)\n",
    "\n",
    "response_labels = ['Disliked', 'Liked']\n",
    "\n",
    "# Iterate through measures to generate plots\n",
    "for i, measure in enumerate(measures):\n",
    "    pre_congruent, post_congruent, pre_incongruent, post_incongruent = process_data(shared_folder_path, measure['pre_file_name'], measure['post_file_name'], response_column, measure['measure_column'])\n",
    "\n",
    "    avg_pre_c, avg_post_c, std_pre_c, std_post_c, p_values_c, t_stats_c, dfs_c = calculate_statistics(pre_congruent, post_congruent)\n",
    "    avg_pre_i, avg_post_i, std_pre_i, std_post_i, p_values_i, t_stats_i, dfs_i = calculate_statistics(pre_incongruent, post_incongruent)\n",
    "\n",
    "    plot_measure_results(axes[i, 0], avg_pre_c, avg_post_c, std_pre_c, std_post_c, p_values_c, t_stats_c, dfs_c, response_labels, measure['ylabel'], f\"Congruent-start - {measure['title']}\")\n",
    "    plot_measure_results(axes[i, 1], avg_pre_i, avg_post_i, std_pre_i, std_post_i, p_values_i, t_stats_i, dfs_i, response_labels, measure['ylabel'], f\"Incongruent-start - {measure['title']}\")\n",
    "\n",
    "# Custom legend\n",
    "paired_palette = sns.color_palette(\"Paired\")\n",
    "custom_legend = [\n",
    "    plt.Line2D([0], [0], color=paired_palette[8], lw=4),\n",
    "    plt.Line2D([0], [0], color=paired_palette[9], lw=4),\n",
    "    plt.Line2D([0], [0], color=paired_palette[6], lw=4),\n",
    "    plt.Line2D([0], [0], color=paired_palette[7], lw=4),\n",
    "]\n",
    "\n",
    "fig.legend(custom_legend, \n",
    "           ['Pre-task (Liked)', 'Post-task (Liked)', 'Pre-task (Disliked)', 'Post-task (Disliked)'], \n",
    "           fontsize=22, loc='lower center', ncol=4, bbox_to_anchor=(0.5, -0.03))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be0f2f0",
   "metadata": {},
   "source": [
    "# Comprehension check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Access the shared folder\n",
    "shared_folder_path = \"\"\n",
    "\n",
    "# Dictionary to hold DataFrames for each participant\n",
    "participant_data = {}\n",
    "participants_without_data = []\n",
    "\n",
    "# List to collect 'accuracy' data from each participant\n",
    "accuracy_data = []\n",
    "\n",
    "# Iterate through each subject folder\n",
    "for subject_folder in os.listdir(shared_folder_path):\n",
    "    subject_folder_path = os.path.join(shared_folder_path, subject_folder)\n",
    "\n",
    "    # Check if the item is a directory (subject folder)\n",
    "    if os.path.isdir(subject_folder_path):\n",
    "        # Construct the path to the ratings CSV file (e.g., practice_trials_test.csv)\n",
    "        task_file_name = \"practice_trials_test.csv\"\n",
    "        task_file_path = os.path.join(subject_folder_path, task_file_name)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(task_file_path):\n",
    "            # Read the task CSV file into a DataFrame\n",
    "            df = pd.read_csv(task_file_path)\n",
    "\n",
    "            # Store the DataFrame in the dictionary with the subject ID as the key\n",
    "            participant_data[subject_folder] = df\n",
    "            \n",
    "            # Collect 'accuracy' data\n",
    "            if 'accuracy' in df.columns:\n",
    "                accuracies = df['accuracy'].dropna().tolist()\n",
    "                accuracy_data.extend(accuracies)\n",
    "            else:\n",
    "                print(f\"'accuracy' column not found in {task_file_name} for participant {subject_folder}\")\n",
    "\n",
    "        else:\n",
    "            participants_without_data.append(subject_folder)\n",
    "            print(f\"No data found for participant {subject_folder}.\")\n",
    "\n",
    "# Report the number of participants\n",
    "total_participants = len(participant_data) + len(participants_without_data)\n",
    "print(f\"\\nTotal participants processed: {total_participants}\")\n",
    "\n",
    "# Final message based on loading status\n",
    "if not participants_without_data:\n",
    "    print(\"Data loaded successfully for all participants.\")\n",
    "else:\n",
    "    print(\"Some participants did not have data loaded:\")\n",
    "    for participant in participants_without_data:\n",
    "        print(f\"- {participant}\")\n",
    "\n",
    "# Summary statistics for 'accuracy' column\n",
    "if accuracy_data:\n",
    "    accuracy_series = pd.Series(accuracy_data)\n",
    "    summary_stats = accuracy_series.describe()\n",
    "    print(\"\\nSummary Statistics for 'accuracy' column across all participants:\")\n",
    "    print(summary_stats)\n",
    "    print(f\"Range: {accuracy_series.min()} - {accuracy_series.max()}\")\n",
    "\n",
    "    # Count plot of accuracies and printing counts for each category\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    count_data = accuracy_series.value_counts().sort_index()\n",
    "    count_data = count_data.reindex([25, 50, 75, 100], fill_value=0)\n",
    "    count_data.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Count Plot of Subject Accuracies')\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Number of Participants')\n",
    "    plt.xticks(rotation=0)  # Rotate x-ticks for better readability\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Printing counts for each category\n",
    "    print(\"\\nCounts for each accuracy category:\")\n",
    "    for accuracy, count in count_data.items():\n",
    "        print(f\"{accuracy}%: {count} participants\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo 'accuracy' data found across all participants.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
